2017-03-08 13:58:49,519 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = gaurav-Inspiron-3542/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-digester-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsch-0.1.42.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-net-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.7.0_111
************************************************************/
2017-03-08 13:58:49,527 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2017-03-08 13:58:50,707 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2017-03-08 13:58:50,709 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2017-03-08 13:58:50,709 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2017-03-08 13:58:50,710 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2017-03-08 13:58:50,710 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2017-03-08 13:58:50,711 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2017-03-08 13:58:50,767 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2017-03-08 13:58:50,768 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2017-03-08 13:58:50,799 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-03-08 13:58:50,857 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-03-08 13:58:50,857 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2017-03-08 13:58:50,955 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2017-03-08 13:58:50,956 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2017-03-08 13:58:50,957 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2017-03-08 13:58:50,992 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2017-03-08 13:58:51,048 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2017-03-08 13:58:51,048 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2017-03-08 13:58:51,116 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@31789ec6
2017-03-08 13:58:51,116 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2017-03-08 13:58:51,116 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2017-03-08 13:58:51,116 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2017-03-08 13:58:51,133 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (3.8 G). Thrashing might happen.
2017-03-08 13:58:51,165 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2017-03-08 13:58:51,239 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-08 13:58:51,254 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 33958
2017-03-08 13:58:51,297 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2017-03-08 13:58:51,297 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2017-03-08 13:58:51,298 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 33958: starting
2017-03-08 13:58:51,298 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-08 13:58:51,313 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : gaurav-Inspiron-3542:33958
2017-03-08 13:58:51,323 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-08 13:58:51,324 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2017-03-08 13:58:51,327 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2017-03-08 13:58:51,328 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-08 13:58:51,328 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2017-03-08 13:58:51,329 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2017-03-08 13:58:51,365 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2017-03-08 13:58:51,375 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2017-03-08 13:58:51,377 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at gaurav-Inspiron-3542/127.0.1.1:33958
2017-03-08 13:58:51,377 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2017-03-08 13:58:51,383 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2017-03-08 13:58:51,448 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-03-08 13:58:51,459 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-03-08 13:58:51,465 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2017-03-08 13:58:51,474 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-03-08 13:58:51,476 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2017-03-08 13:58:51,476 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-03-08 13:58:51,477 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-03-08 13:58:51,481 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /node/*
2017-03-08 13:58:51,481 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2017-03-08 13:58:51,907 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2017-03-08 13:58:51,909 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2017-03-08 13:58:51,909 INFO org.mortbay.log: jetty-6.1.26
2017-03-08 13:58:51,930 INFO org.mortbay.log: Extract jar:file:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2017-03-08 13:58:53,154 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-08 13:58:53,154 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2017-03-08 13:58:53,175 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /192.168.43.107:8025
2017-03-08 13:58:53,196 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out 0 NM container statuses: []
2017-03-08 13:58:53,208 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registering with RM using containers :[]
2017-03-08 13:58:54,364 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id -1288490961
2017-03-08 13:58:54,385 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id -1872810550
2017-03-08 13:58:54,386 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as gaurav-Inspiron-3542:33958 with total resource of <memory:8192, vCores:8>
2017-03-08 13:58:54,386 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2017-03-08 13:59:55,666 ERROR org.apache.hadoop.yarn.server.nodemanager.NodeManager: RECEIVED SIGNAL 15: SIGTERM
2017-03-08 13:59:55,695 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-08 13:59:55,795 INFO org.apache.hadoop.ipc.Server: Stopping server on 33958
2017-03-08 13:59:55,796 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 33958
2017-03-08 13:59:55,797 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-08 13:59:55,797 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl is interrupted. Exiting.
2017-03-08 13:59:55,806 INFO org.apache.hadoop.ipc.Server: Stopping server on 8040
2017-03-08 13:59:55,807 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8040
2017-03-08 13:59:55,807 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-08 13:59:55,808 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NodeManager metrics system...
2017-03-08 13:59:55,808 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Public cache exiting
2017-03-08 13:59:55,808 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system stopped.
2017-03-08 13:59:55,809 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system shutdown complete.
2017-03-08 13:59:55,809 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NodeManager at gaurav-Inspiron-3542/127.0.1.1
************************************************************/
2017-03-08 14:00:43,114 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = gaurav-Inspiron-3542/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-digester-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsch-0.1.42.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-net-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.7.0_111
************************************************************/
2017-03-08 14:00:43,123 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2017-03-08 14:00:44,167 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2017-03-08 14:00:44,168 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2017-03-08 14:00:44,169 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2017-03-08 14:00:44,169 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2017-03-08 14:00:44,170 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2017-03-08 14:00:44,170 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2017-03-08 14:00:44,190 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2017-03-08 14:00:44,191 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2017-03-08 14:00:44,222 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-03-08 14:00:44,280 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-03-08 14:00:44,280 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2017-03-08 14:00:44,300 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2017-03-08 14:00:44,302 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2017-03-08 14:00:44,302 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2017-03-08 14:00:44,327 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/tmp/hadoop-hadoop/nm-local-dir/usercache_DEL_1488961844305
2017-03-08 14:00:44,371 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2017-03-08 14:00:44,392 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2017-03-08 14:00:44,392 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2017-03-08 14:00:44,424 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@48a3de69
2017-03-08 14:00:44,425 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2017-03-08 14:00:44,425 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2017-03-08 14:00:44,425 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2017-03-08 14:00:44,429 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (3.8 G). Thrashing might happen.
2017-03-08 14:00:44,432 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2017-03-08 14:00:44,494 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-08 14:00:44,510 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 35366
2017-03-08 14:00:44,553 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2017-03-08 14:00:44,553 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2017-03-08 14:00:44,553 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-08 14:00:44,553 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 35366: starting
2017-03-08 14:00:44,559 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : gaurav-Inspiron-3542:35366
2017-03-08 14:00:44,568 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-08 14:00:44,568 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2017-03-08 14:00:44,571 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2017-03-08 14:00:44,572 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2017-03-08 14:00:44,572 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-08 14:00:44,572 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2017-03-08 14:00:44,583 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2017-03-08 14:00:44,593 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2017-03-08 14:00:44,595 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at gaurav-Inspiron-3542/127.0.1.1:35366
2017-03-08 14:00:44,595 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2017-03-08 14:00:44,596 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2017-03-08 14:00:44,658 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-03-08 14:00:44,666 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-03-08 14:00:44,671 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2017-03-08 14:00:44,678 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-03-08 14:00:44,681 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2017-03-08 14:00:44,681 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-03-08 14:00:44,681 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-03-08 14:00:44,685 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /node/*
2017-03-08 14:00:44,685 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2017-03-08 14:00:44,993 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2017-03-08 14:00:44,994 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2017-03-08 14:00:44,995 INFO org.mortbay.log: jetty-6.1.26
2017-03-08 14:00:45,015 INFO org.mortbay.log: Extract jar:file:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2017-03-08 14:00:45,967 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-08 14:00:45,967 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2017-03-08 14:00:45,973 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /192.168.43.107:8025
2017-03-08 14:00:45,993 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out 0 NM container statuses: []
2017-03-08 14:00:45,997 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registering with RM using containers :[]
2017-03-08 14:00:47,313 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 1983030296
2017-03-08 14:00:47,318 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id -1507352085
2017-03-08 14:00:47,319 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as gaurav-Inspiron-3542:35366 with total resource of <memory:8192, vCores:8>
2017-03-08 14:00:47,319 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2017-03-08 14:03:14,190 ERROR org.apache.hadoop.yarn.server.nodemanager.NodeManager: RECEIVED SIGNAL 15: SIGTERM
2017-03-08 14:03:14,195 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-08 14:03:14,296 INFO org.apache.hadoop.ipc.Server: Stopping server on 35366
2017-03-08 14:03:14,296 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 35366
2017-03-08 14:03:14,298 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl is interrupted. Exiting.
2017-03-08 14:03:14,299 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-08 14:03:14,306 INFO org.apache.hadoop.ipc.Server: Stopping server on 8040
2017-03-08 14:03:14,307 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8040
2017-03-08 14:03:14,308 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Public cache exiting
2017-03-08 14:03:14,308 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-08 14:03:14,308 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NodeManager metrics system...
2017-03-08 14:03:14,309 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system stopped.
2017-03-08 14:03:14,309 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system shutdown complete.
2017-03-08 14:03:14,309 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NodeManager at gaurav-Inspiron-3542/127.0.1.1
************************************************************/
2017-03-08 14:04:38,090 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = gaurav-Inspiron-3542/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-digester-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsch-0.1.42.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-net-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.7.0_111
************************************************************/
2017-03-08 14:04:38,101 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2017-03-08 14:04:39,204 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2017-03-08 14:04:39,206 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2017-03-08 14:04:39,206 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2017-03-08 14:04:39,207 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2017-03-08 14:04:39,208 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2017-03-08 14:04:39,208 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2017-03-08 14:04:39,241 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2017-03-08 14:04:39,241 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2017-03-08 14:04:39,283 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-03-08 14:04:39,354 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-03-08 14:04:39,354 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2017-03-08 14:04:39,379 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2017-03-08 14:04:39,381 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2017-03-08 14:04:39,381 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2017-03-08 14:04:39,408 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/tmp/hadoop-hadoop/nm-local-dir/usercache_DEL_1488962079385
2017-03-08 14:04:39,463 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2017-03-08 14:04:39,493 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2017-03-08 14:04:39,493 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2017-03-08 14:04:39,540 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@396729a9
2017-03-08 14:04:39,540 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2017-03-08 14:04:39,540 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2017-03-08 14:04:39,540 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2017-03-08 14:04:39,545 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (3.8 G). Thrashing might happen.
2017-03-08 14:04:39,551 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2017-03-08 14:04:39,589 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-08 14:04:39,607 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 54524
2017-03-08 14:04:39,660 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2017-03-08 14:04:39,661 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2017-03-08 14:04:39,661 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-08 14:04:39,662 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 54524: starting
2017-03-08 14:04:39,668 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : gaurav-Inspiron-3542:54524
2017-03-08 14:04:39,678 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-08 14:04:39,679 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2017-03-08 14:04:39,682 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2017-03-08 14:04:39,683 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-08 14:04:39,683 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2017-03-08 14:04:39,684 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2017-03-08 14:04:39,697 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2017-03-08 14:04:39,709 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2017-03-08 14:04:39,712 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at gaurav-Inspiron-3542/127.0.1.1:54524
2017-03-08 14:04:39,712 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2017-03-08 14:04:39,713 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2017-03-08 14:04:39,788 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-03-08 14:04:39,800 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-03-08 14:04:39,806 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2017-03-08 14:04:39,816 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-03-08 14:04:39,819 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2017-03-08 14:04:39,819 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-03-08 14:04:39,819 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-03-08 14:04:39,824 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /node/*
2017-03-08 14:04:39,824 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2017-03-08 14:04:40,144 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2017-03-08 14:04:40,146 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2017-03-08 14:04:40,146 INFO org.mortbay.log: jetty-6.1.26
2017-03-08 14:04:40,166 INFO org.mortbay.log: Extract jar:file:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2017-03-08 14:04:41,092 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-08 14:04:41,092 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2017-03-08 14:04:41,097 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /192.168.43.107:8025
2017-03-08 14:04:41,117 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out 0 NM container statuses: []
2017-03-08 14:04:41,122 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registering with RM using containers :[]
2017-03-08 14:04:42,142 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 881563373
2017-03-08 14:04:42,147 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id 351704501
2017-03-08 14:04:42,148 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as gaurav-Inspiron-3542:54524 with total resource of <memory:8192, vCores:8>
2017-03-08 14:04:42,148 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2017-03-08 21:13:21,400 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-08 21:13:21,400 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); maxRetries=45
2017-03-08 21:13:22,400 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-08 21:13:23,401 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-08 21:13:24,401 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-08 21:13:25,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-08 21:13:26,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-08 21:13:27,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-08 21:13:28,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-08 21:13:29,405 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-08 21:13:30,406 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-08 21:13:31,406 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-08 21:14:01,409 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-08 21:14:02,409 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-08 21:14:03,410 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-08 21:14:04,411 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-08 21:14:05,411 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-08 21:14:06,412 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-08 21:14:07,413 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-08 21:14:08,413 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-08 21:14:09,414 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-08 21:14:10,414 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-08 21:14:11,415 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-08 21:14:41,417 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-08 21:14:42,417 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-08 21:14:43,418 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-08 21:14:44,419 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-08 21:14:45,419 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-08 21:14:46,420 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-08 21:14:47,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-08 21:14:48,422 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-08 21:14:49,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-08 21:14:50,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-08 21:14:51,424 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-08 21:15:42,008 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-08 21:15:42,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); maxRetries=45
2017-03-08 21:16:02,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); maxRetries=45
2017-03-08 21:16:22,036 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); maxRetries=45
2017-03-08 21:16:42,057 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); maxRetries=45
2017-03-08 21:17:02,078 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); maxRetries=45
2017-03-08 21:17:22,080 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); maxRetries=45
2017-03-08 21:17:42,102 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); maxRetries=45
2017-03-08 21:18:02,113 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); maxRetries=45
2017-03-08 21:18:22,131 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); maxRetries=45
2017-03-08 21:18:42,152 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); maxRetries=45
2017-03-08 21:19:02,172 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 10 time(s); maxRetries=45
2017-03-08 21:19:22,193 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 11 time(s); maxRetries=45
2017-03-08 21:19:42,197 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 12 time(s); maxRetries=45
2017-03-08 21:20:02,205 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 13 time(s); maxRetries=45
2017-03-08 21:20:22,226 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 14 time(s); maxRetries=45
2017-03-08 21:20:42,236 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 15 time(s); maxRetries=45
2017-03-08 21:21:02,257 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 16 time(s); maxRetries=45
2017-03-08 21:21:22,267 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 17 time(s); maxRetries=45
2017-03-08 21:21:42,288 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 18 time(s); maxRetries=45
2017-03-08 21:22:02,309 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 19 time(s); maxRetries=45
2017-03-08 21:22:22,330 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 20 time(s); maxRetries=45
2017-03-08 21:22:42,338 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 21 time(s); maxRetries=45
2017-03-08 21:23:02,359 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 22 time(s); maxRetries=45
2017-03-08 21:23:22,379 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 23 time(s); maxRetries=45
2017-03-08 21:23:42,390 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 24 time(s); maxRetries=45
2017-03-08 21:24:02,410 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 25 time(s); maxRetries=45
2017-03-08 21:24:22,424 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 26 time(s); maxRetries=45
2017-03-08 21:24:42,442 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 27 time(s); maxRetries=45
2017-03-08 21:25:02,463 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 28 time(s); maxRetries=45
2017-03-08 21:25:22,466 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 29 time(s); maxRetries=45
2017-03-08 21:25:42,470 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 30 time(s); maxRetries=45
2017-03-08 21:26:02,490 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 31 time(s); maxRetries=45
2017-03-08 21:26:22,511 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 32 time(s); maxRetries=45
2017-03-08 21:26:42,532 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 33 time(s); maxRetries=45
2017-03-08 21:27:02,553 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 34 time(s); maxRetries=45
2017-03-08 21:27:22,574 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 35 time(s); maxRetries=45
2017-03-08 21:27:42,578 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 36 time(s); maxRetries=45
2017-03-08 21:28:02,584 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 37 time(s); maxRetries=45
2017-03-08 21:28:22,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 38 time(s); maxRetries=45
2017-03-08 21:28:42,605 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 39 time(s); maxRetries=45
2017-03-08 21:29:02,626 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 40 time(s); maxRetries=45
2017-03-08 21:29:22,647 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 41 time(s); maxRetries=45
2017-03-08 21:29:42,649 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 42 time(s); maxRetries=45
2017-03-08 21:30:02,670 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 43 time(s); maxRetries=45
2017-03-08 21:30:22,691 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 44 time(s); maxRetries=45
2017-03-08 21:31:32,718 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-08 21:31:32,718 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); maxRetries=45
2017-03-08 21:31:52,739 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); maxRetries=45
2017-03-08 21:32:12,751 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); maxRetries=45
2017-03-08 21:32:32,772 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); maxRetries=45
2017-03-08 21:32:52,775 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); maxRetries=45
2017-03-08 21:33:12,796 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); maxRetries=45
2017-03-08 21:33:32,817 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); maxRetries=45
2017-03-08 21:33:52,838 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); maxRetries=45
2017-03-08 21:34:12,844 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); maxRetries=45
2017-03-08 21:34:32,865 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); maxRetries=45
2017-03-08 21:34:52,868 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 10 time(s); maxRetries=45
2017-03-08 21:35:12,886 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 11 time(s); maxRetries=45
2017-03-08 21:35:32,889 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 12 time(s); maxRetries=45
2017-03-08 21:35:52,904 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 13 time(s); maxRetries=45
2017-03-08 21:36:12,922 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 14 time(s); maxRetries=45
2017-03-08 21:36:32,943 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 15 time(s); maxRetries=45
2017-03-08 21:36:52,951 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 16 time(s); maxRetries=45
2017-03-08 21:37:12,972 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 17 time(s); maxRetries=45
2017-03-08 21:37:32,993 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 18 time(s); maxRetries=45
2017-03-08 21:37:53,010 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 19 time(s); maxRetries=45
2017-03-08 21:38:13,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 20 time(s); maxRetries=45
2017-03-08 21:38:33,043 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 21 time(s); maxRetries=45
2017-03-08 21:38:53,064 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 22 time(s); maxRetries=45
2017-03-08 21:39:13,074 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 23 time(s); maxRetries=45
2017-03-08 21:39:33,087 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 24 time(s); maxRetries=45
2017-03-08 21:39:53,107 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 25 time(s); maxRetries=45
2017-03-08 21:40:13,117 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 26 time(s); maxRetries=45
2017-03-08 21:40:33,137 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 27 time(s); maxRetries=45
2017-03-08 21:40:53,156 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 28 time(s); maxRetries=45
2017-03-08 21:41:13,177 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 29 time(s); maxRetries=45
2017-03-08 21:41:33,198 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 30 time(s); maxRetries=45
2017-03-08 21:41:53,214 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 31 time(s); maxRetries=45
2017-03-08 21:42:13,235 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 32 time(s); maxRetries=45
2017-03-08 21:42:33,256 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 33 time(s); maxRetries=45
2017-03-08 21:42:53,277 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 34 time(s); maxRetries=45
2017-03-08 21:43:13,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 35 time(s); maxRetries=45
2017-03-08 21:43:33,304 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 36 time(s); maxRetries=45
2017-03-08 21:43:53,325 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 37 time(s); maxRetries=45
2017-03-08 21:44:13,335 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 38 time(s); maxRetries=45
2017-03-08 21:44:33,354 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 39 time(s); maxRetries=45
2017-03-08 21:44:53,367 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 40 time(s); maxRetries=45
2017-03-08 21:45:13,388 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 41 time(s); maxRetries=45
2017-03-08 21:45:33,409 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 42 time(s); maxRetries=45
2017-03-08 21:45:53,430 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 43 time(s); maxRetries=45
2017-03-08 21:46:13,438 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 44 time(s); maxRetries=45
2017-03-08 21:47:23,481 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-08 21:47:23,482 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); maxRetries=45
2017-03-08 21:47:43,502 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); maxRetries=45
2017-03-08 21:48:03,510 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); maxRetries=45
2017-03-08 21:48:23,531 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); maxRetries=45
2017-03-08 21:48:43,553 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); maxRetries=45
2017-03-08 21:49:03,573 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); maxRetries=45
2017-03-08 21:49:23,586 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); maxRetries=45
2017-03-08 21:49:43,607 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); maxRetries=45
2017-03-08 21:50:03,628 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); maxRetries=45
2017-03-08 21:50:23,649 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); maxRetries=45
2017-03-08 21:50:43,670 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 10 time(s); maxRetries=45
2017-03-08 21:51:03,691 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 11 time(s); maxRetries=45
2017-03-08 21:51:23,699 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 12 time(s); maxRetries=45
2017-03-08 21:51:43,702 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 13 time(s); maxRetries=45
2017-03-08 21:52:03,706 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 14 time(s); maxRetries=45
2017-03-08 21:52:23,709 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 15 time(s); maxRetries=45
2017-03-08 21:52:43,725 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 16 time(s); maxRetries=45
2017-03-08 21:53:03,738 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 17 time(s); maxRetries=45
2017-03-08 21:53:23,759 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 18 time(s); maxRetries=45
2017-03-08 21:53:43,780 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 19 time(s); maxRetries=45
2017-03-08 21:54:03,801 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 20 time(s); maxRetries=45
2017-03-08 21:54:23,806 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 21 time(s); maxRetries=45
2017-03-08 21:54:43,827 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 22 time(s); maxRetries=45
2017-03-08 21:55:03,848 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 23 time(s); maxRetries=45
2017-03-08 21:55:23,869 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 24 time(s); maxRetries=45
2017-03-08 21:55:43,884 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 25 time(s); maxRetries=45
2017-03-08 21:56:03,905 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 26 time(s); maxRetries=45
2017-03-08 21:56:23,919 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 27 time(s); maxRetries=45
2017-03-08 21:56:43,940 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 28 time(s); maxRetries=45
2017-03-08 21:57:03,959 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 29 time(s); maxRetries=45
2017-03-08 21:57:23,980 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 30 time(s); maxRetries=45
2017-03-08 21:57:44,001 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 31 time(s); maxRetries=45
2017-03-08 21:58:04,022 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 32 time(s); maxRetries=45
2017-03-08 21:58:24,043 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 33 time(s); maxRetries=45
2017-03-08 21:58:44,065 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 34 time(s); maxRetries=45
2017-03-08 21:59:04,085 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 35 time(s); maxRetries=45
2017-03-08 21:59:24,107 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 36 time(s); maxRetries=45
2017-03-08 21:59:44,128 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 37 time(s); maxRetries=45
2017-03-08 22:00:04,141 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 38 time(s); maxRetries=45
2017-03-08 22:00:24,162 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 39 time(s); maxRetries=45
2017-03-08 22:00:44,173 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 40 time(s); maxRetries=45
2017-03-08 22:01:04,190 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 41 time(s); maxRetries=45
2017-03-08 22:01:24,211 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 42 time(s); maxRetries=45
2017-03-08 22:01:44,221 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 43 time(s); maxRetries=45
2017-03-08 22:02:04,226 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 44 time(s); maxRetries=45
2017-03-08 22:03:14,266 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-08 22:03:14,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); maxRetries=45
2017-03-08 22:03:34,271 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); maxRetries=45
2017-03-08 22:03:54,292 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); maxRetries=45
2017-03-08 22:04:14,308 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); maxRetries=45
2017-03-08 22:04:34,322 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); maxRetries=45
2017-03-08 22:04:54,339 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); maxRetries=45
2017-03-08 22:05:14,348 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); maxRetries=45
2017-03-08 22:05:34,369 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); maxRetries=45
2017-03-08 22:05:54,390 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); maxRetries=45
2017-03-08 22:06:14,410 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); maxRetries=45
2017-03-08 22:06:34,413 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 10 time(s); maxRetries=45
2017-03-08 22:06:54,422 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 11 time(s); maxRetries=45
2017-03-08 22:07:14,431 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 12 time(s); maxRetries=45
2017-03-08 22:07:34,446 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 13 time(s); maxRetries=45
2017-03-08 22:07:54,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 14 time(s); maxRetries=45
2017-03-08 22:08:14,474 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 15 time(s); maxRetries=45
2017-03-08 22:08:34,491 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 16 time(s); maxRetries=45
2017-03-08 22:08:54,504 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 17 time(s); maxRetries=45
2017-03-08 22:09:14,516 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 18 time(s); maxRetries=45
2017-03-08 22:09:34,525 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 19 time(s); maxRetries=45
2017-03-08 22:09:54,539 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 20 time(s); maxRetries=45
2017-03-08 22:10:14,550 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 21 time(s); maxRetries=45
2017-03-08 22:10:34,571 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 22 time(s); maxRetries=45
2017-03-08 22:10:54,592 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 23 time(s); maxRetries=45
2017-03-08 22:11:14,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 24 time(s); maxRetries=45
2017-03-08 22:11:34,627 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 25 time(s); maxRetries=45
2017-03-08 22:11:54,647 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 26 time(s); maxRetries=45
2017-03-08 22:12:14,668 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 27 time(s); maxRetries=45
2017-03-08 22:12:34,689 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 28 time(s); maxRetries=45
2017-03-08 22:12:54,709 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 29 time(s); maxRetries=45
2017-03-08 22:13:14,715 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 30 time(s); maxRetries=45
2017-03-08 22:13:34,736 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 31 time(s); maxRetries=45
2017-03-08 22:13:54,738 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 32 time(s); maxRetries=45
2017-03-08 22:14:14,742 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 33 time(s); maxRetries=45
2017-03-08 22:14:34,743 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 34 time(s); maxRetries=45
2017-03-08 22:14:54,763 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 35 time(s); maxRetries=45
2017-03-08 22:15:14,783 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 36 time(s); maxRetries=45
2017-03-08 22:15:34,794 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 37 time(s); maxRetries=45
2017-03-08 22:15:54,816 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 38 time(s); maxRetries=45
2017-03-08 22:16:14,837 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 39 time(s); maxRetries=45
2017-03-08 22:16:34,848 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 40 time(s); maxRetries=45
2017-03-08 22:16:54,848 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 41 time(s); maxRetries=45
2017-03-08 22:17:14,865 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 42 time(s); maxRetries=45
2017-03-08 22:17:34,882 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 43 time(s); maxRetries=45
2017-03-08 22:17:54,903 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 44 time(s); maxRetries=45
2017-03-08 22:19:04,919 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-08 22:19:04,920 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); maxRetries=45
2017-03-08 22:19:24,936 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); maxRetries=45
2017-03-08 22:19:44,956 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); maxRetries=45
2017-03-08 22:20:04,977 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); maxRetries=45
2017-03-08 22:20:24,999 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); maxRetries=45
2017-03-08 22:20:45,020 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); maxRetries=45
2017-03-08 22:21:05,041 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); maxRetries=45
2017-03-08 22:21:25,061 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); maxRetries=45
2017-03-08 22:21:45,082 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); maxRetries=45
2017-03-08 22:22:05,103 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); maxRetries=45
2017-03-08 22:22:25,124 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 10 time(s); maxRetries=45
2017-03-08 22:22:45,138 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 11 time(s); maxRetries=45
2017-03-08 22:23:05,158 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 12 time(s); maxRetries=45
2017-03-08 22:23:25,177 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 13 time(s); maxRetries=45
2017-03-08 22:23:45,194 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 14 time(s); maxRetries=45
2017-03-08 22:24:05,214 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 15 time(s); maxRetries=45
2017-03-08 22:24:25,218 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 16 time(s); maxRetries=45
2017-03-08 22:24:45,219 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 17 time(s); maxRetries=45
2017-03-08 22:25:05,240 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 18 time(s); maxRetries=45
2017-03-08 22:25:25,259 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 19 time(s); maxRetries=45
2017-03-08 22:25:45,278 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 20 time(s); maxRetries=45
2017-03-08 22:26:05,299 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 21 time(s); maxRetries=45
2017-03-08 22:26:25,319 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 22 time(s); maxRetries=45
2017-03-08 22:26:45,334 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 23 time(s); maxRetries=45
2017-03-08 22:27:05,356 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 24 time(s); maxRetries=45
2017-03-08 22:27:25,377 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 25 time(s); maxRetries=45
2017-03-08 22:27:45,394 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 26 time(s); maxRetries=45
2017-03-08 22:28:05,415 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 27 time(s); maxRetries=45
2017-03-08 22:28:25,437 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 28 time(s); maxRetries=45
2017-03-08 22:28:45,457 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 29 time(s); maxRetries=45
2017-03-08 22:29:05,479 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 30 time(s); maxRetries=45
2017-03-08 22:29:25,492 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 31 time(s); maxRetries=45
2017-03-08 22:29:45,510 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 32 time(s); maxRetries=45
2017-03-08 22:30:05,531 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 33 time(s); maxRetries=45
2017-03-08 22:30:25,551 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 34 time(s); maxRetries=45
2017-03-08 22:30:45,572 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 35 time(s); maxRetries=45
2017-03-08 22:31:05,594 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 36 time(s); maxRetries=45
2017-03-08 22:31:25,615 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 37 time(s); maxRetries=45
2017-03-08 22:31:45,636 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 38 time(s); maxRetries=45
2017-03-08 22:32:05,657 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 39 time(s); maxRetries=45
2017-03-08 22:32:25,678 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 40 time(s); maxRetries=45
2017-03-08 22:32:45,699 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 41 time(s); maxRetries=45
2017-03-08 22:33:05,712 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 42 time(s); maxRetries=45
2017-03-08 22:33:25,726 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 43 time(s); maxRetries=45
2017-03-08 22:33:45,740 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 44 time(s); maxRetries=45
2017-03-08 22:34:55,775 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-08 22:34:55,776 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); maxRetries=45
2017-03-08 22:35:15,797 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); maxRetries=45
2017-03-08 22:35:35,818 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); maxRetries=45
2017-03-08 22:35:55,839 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); maxRetries=45
2017-03-08 22:36:15,853 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); maxRetries=45
2017-03-08 22:36:35,874 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); maxRetries=45
2017-03-08 22:36:55,895 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); maxRetries=45
2017-03-08 22:37:15,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); maxRetries=45
2017-03-08 22:37:35,937 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); maxRetries=45
2017-03-08 22:37:55,958 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); maxRetries=45
2017-03-08 22:38:15,979 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 10 time(s); maxRetries=45
2017-03-08 22:38:35,984 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 11 time(s); maxRetries=45
2017-03-08 22:38:56,005 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 12 time(s); maxRetries=45
2017-03-08 22:39:16,026 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 13 time(s); maxRetries=45
2017-03-08 22:39:36,048 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 14 time(s); maxRetries=45
2017-03-08 22:39:56,068 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 15 time(s); maxRetries=45
2017-03-08 22:40:16,090 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 16 time(s); maxRetries=45
2017-03-08 22:40:36,110 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 17 time(s); maxRetries=45
2017-03-08 22:40:56,125 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 18 time(s); maxRetries=45
2017-03-08 22:41:16,139 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 19 time(s); maxRetries=45
2017-03-08 22:41:36,156 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 20 time(s); maxRetries=45
2017-03-08 22:41:56,160 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 21 time(s); maxRetries=45
2017-03-08 22:42:16,164 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 22 time(s); maxRetries=45
2017-03-08 22:42:36,185 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 23 time(s); maxRetries=45
2017-03-08 22:42:56,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 24 time(s); maxRetries=45
2017-03-08 22:43:16,227 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 25 time(s); maxRetries=45
2017-03-08 22:43:36,248 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 26 time(s); maxRetries=45
2017-03-08 22:43:56,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 27 time(s); maxRetries=45
2017-03-08 22:44:16,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 28 time(s); maxRetries=45
2017-03-08 22:44:36,311 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 29 time(s); maxRetries=45
2017-03-08 22:44:56,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 30 time(s); maxRetries=45
2017-03-08 22:45:16,353 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 31 time(s); maxRetries=45
2017-03-08 22:45:36,375 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 32 time(s); maxRetries=45
2017-03-08 22:45:56,396 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 33 time(s); maxRetries=45
2017-03-08 22:46:16,417 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 34 time(s); maxRetries=45
2017-03-08 22:46:36,438 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 35 time(s); maxRetries=45
2017-03-08 22:46:56,451 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 36 time(s); maxRetries=45
2017-03-08 22:47:16,469 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 37 time(s); maxRetries=45
2017-03-08 22:47:36,471 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 38 time(s); maxRetries=45
2017-03-08 22:47:56,491 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 39 time(s); maxRetries=45
2017-03-08 22:48:16,504 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 40 time(s); maxRetries=45
2017-03-08 22:48:36,524 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 41 time(s); maxRetries=45
2017-03-08 22:48:56,529 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 42 time(s); maxRetries=45
2017-03-08 22:49:16,550 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 43 time(s); maxRetries=45
2017-03-08 22:49:36,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 44 time(s); maxRetries=45
2017-03-08 22:50:46,590 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-08 22:50:46,590 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); maxRetries=45
2017-03-08 22:51:06,611 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); maxRetries=45
2017-03-08 22:51:26,632 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); maxRetries=45
2017-03-08 22:51:46,653 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); maxRetries=45
2017-03-08 22:52:06,674 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); maxRetries=45
2017-03-08 22:52:26,688 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); maxRetries=45
2017-03-08 22:52:46,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); maxRetries=45
2017-03-08 22:53:06,722 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); maxRetries=45
2017-03-08 22:53:26,742 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); maxRetries=45
2017-03-08 22:53:46,762 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); maxRetries=45
2017-03-08 22:54:06,775 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 10 time(s); maxRetries=45
2017-03-08 22:54:26,777 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 11 time(s); maxRetries=45
2017-03-08 22:54:46,797 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 12 time(s); maxRetries=45
2017-03-08 22:55:06,818 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 13 time(s); maxRetries=45
2017-03-08 22:55:26,838 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 14 time(s); maxRetries=45
2017-03-08 22:55:46,859 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 15 time(s); maxRetries=45
2017-03-08 22:56:06,880 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 16 time(s); maxRetries=45
2017-03-08 22:56:26,894 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 17 time(s); maxRetries=45
2017-03-08 22:56:46,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 18 time(s); maxRetries=45
2017-03-08 22:57:06,932 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 19 time(s); maxRetries=45
2017-03-08 22:57:26,950 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 20 time(s); maxRetries=45
2017-03-08 22:57:46,955 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 21 time(s); maxRetries=45
2017-03-08 22:58:06,974 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 22 time(s); maxRetries=45
2017-03-08 22:58:26,995 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 23 time(s); maxRetries=45
2017-03-08 22:58:47,007 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 24 time(s); maxRetries=45
2017-03-08 22:59:07,028 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 25 time(s); maxRetries=45
2017-03-08 22:59:27,044 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 26 time(s); maxRetries=45
2017-03-08 22:59:47,057 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 27 time(s); maxRetries=45
2017-03-08 23:00:07,072 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 28 time(s); maxRetries=45
2017-03-08 23:00:27,090 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 29 time(s); maxRetries=45
2017-03-08 23:00:47,111 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 30 time(s); maxRetries=45
2017-03-08 23:01:07,117 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 31 time(s); maxRetries=45
2017-03-08 23:01:27,132 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 32 time(s); maxRetries=45
2017-03-08 23:01:47,150 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 33 time(s); maxRetries=45
2017-03-08 23:02:07,157 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 34 time(s); maxRetries=45
2017-03-08 23:02:27,171 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 35 time(s); maxRetries=45
2017-03-08 23:02:47,192 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 36 time(s); maxRetries=45
2017-03-08 23:03:07,208 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 37 time(s); maxRetries=45
2017-03-08 23:03:27,209 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 38 time(s); maxRetries=45
2017-03-08 23:03:47,219 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 39 time(s); maxRetries=45
2017-03-08 23:04:07,239 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 40 time(s); maxRetries=45
2017-03-08 23:04:27,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 41 time(s); maxRetries=45
2017-03-08 23:04:47,279 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 42 time(s); maxRetries=45
2017-03-08 23:05:07,289 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 43 time(s); maxRetries=45
2017-03-08 23:05:27,311 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 44 time(s); maxRetries=45
2017-03-08 23:06:37,352 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-08 23:06:37,352 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); maxRetries=45
2017-03-08 23:06:57,372 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); maxRetries=45
2017-03-08 23:07:17,379 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); maxRetries=45
2017-03-08 23:07:37,392 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); maxRetries=45
2017-03-08 23:07:57,397 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); maxRetries=45
2017-03-08 23:08:17,418 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); maxRetries=45
2017-03-08 23:08:37,438 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); maxRetries=45
2017-03-08 23:08:57,458 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); maxRetries=45
2017-03-08 23:09:17,472 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); maxRetries=45
2017-03-08 23:09:37,491 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); maxRetries=45
2017-03-08 23:09:57,497 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 10 time(s); maxRetries=45
2017-03-08 23:10:17,518 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 11 time(s); maxRetries=45
2017-03-08 23:10:37,538 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 12 time(s); maxRetries=45
2017-03-08 23:10:57,559 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 13 time(s); maxRetries=45
2017-03-08 23:11:17,560 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 14 time(s); maxRetries=45
2017-03-08 23:11:37,575 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 15 time(s); maxRetries=45
2017-03-08 23:11:57,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 16 time(s); maxRetries=45
2017-03-08 23:12:17,595 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 17 time(s); maxRetries=45
2017-03-08 23:12:37,605 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 18 time(s); maxRetries=45
2017-03-08 23:12:57,612 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 19 time(s); maxRetries=45
2017-03-08 23:13:17,623 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 20 time(s); maxRetries=45
2017-03-08 23:13:37,625 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 21 time(s); maxRetries=45
2017-03-08 23:13:57,639 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 22 time(s); maxRetries=45
2017-03-08 23:14:17,641 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 23 time(s); maxRetries=45
2017-03-08 23:14:37,649 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 24 time(s); maxRetries=45
2017-03-08 23:14:57,665 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 25 time(s); maxRetries=45
2017-03-08 23:15:17,683 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 26 time(s); maxRetries=45
2017-03-08 23:15:37,690 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 27 time(s); maxRetries=45
2017-03-08 23:15:57,710 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 28 time(s); maxRetries=45
2017-03-08 23:16:17,726 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 29 time(s); maxRetries=45
2017-03-08 23:16:37,744 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 30 time(s); maxRetries=45
2017-03-08 23:16:57,765 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 31 time(s); maxRetries=45
2017-03-08 23:17:17,776 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 32 time(s); maxRetries=45
2017-03-08 23:17:37,781 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 33 time(s); maxRetries=45
2017-03-08 23:17:57,798 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 34 time(s); maxRetries=45
2017-03-08 23:18:17,819 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 35 time(s); maxRetries=45
2017-03-08 23:18:37,840 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 36 time(s); maxRetries=45
2017-03-08 23:18:57,861 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 37 time(s); maxRetries=45
2017-03-08 23:19:17,882 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 38 time(s); maxRetries=45
2017-03-08 23:19:37,887 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 39 time(s); maxRetries=45
2017-03-08 23:19:57,908 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 40 time(s); maxRetries=45
2017-03-08 23:20:17,926 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 41 time(s); maxRetries=45
2017-03-08 23:20:37,947 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 42 time(s); maxRetries=45
2017-03-08 23:20:57,960 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 43 time(s); maxRetries=45
2017-03-08 23:21:17,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 44 time(s); maxRetries=45
2017-03-08 23:22:28,006 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-08 23:22:28,006 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); maxRetries=45
2017-03-08 23:22:48,024 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); maxRetries=45
2017-03-08 23:23:08,039 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); maxRetries=45
2017-03-08 23:23:28,044 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); maxRetries=45
2017-03-08 23:23:48,051 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); maxRetries=45
2017-03-08 23:24:08,064 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); maxRetries=45
2017-03-08 23:24:28,065 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); maxRetries=45
2017-03-08 23:24:48,076 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); maxRetries=45
2017-03-08 23:25:08,098 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); maxRetries=45
2017-03-08 23:25:28,105 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); maxRetries=45
2017-03-08 23:25:48,117 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 10 time(s); maxRetries=45
2017-03-08 23:26:08,123 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 11 time(s); maxRetries=45
2017-03-08 23:26:28,132 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 12 time(s); maxRetries=45
2017-03-08 23:26:48,141 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 13 time(s); maxRetries=45
2017-03-08 23:27:08,154 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 14 time(s); maxRetries=45
2017-03-08 23:27:28,171 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 15 time(s); maxRetries=45
2017-03-08 23:27:48,192 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 16 time(s); maxRetries=45
2017-03-08 23:28:08,194 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 17 time(s); maxRetries=45
2017-03-08 23:28:28,215 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 18 time(s); maxRetries=45
2017-03-08 23:28:48,236 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 19 time(s); maxRetries=45
2017-03-08 23:29:08,257 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 20 time(s); maxRetries=45
2017-03-08 23:29:28,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 21 time(s); maxRetries=45
2017-03-08 23:29:48,277 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 22 time(s); maxRetries=45
2017-03-08 23:30:08,293 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 23 time(s); maxRetries=45
2017-03-08 23:30:28,314 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 24 time(s); maxRetries=45
2017-03-08 23:30:48,334 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 25 time(s); maxRetries=45
2017-03-08 23:31:08,355 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 26 time(s); maxRetries=45
2017-03-08 23:31:28,376 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 27 time(s); maxRetries=45
2017-03-08 23:31:48,384 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 28 time(s); maxRetries=45
2017-03-08 23:32:08,393 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 29 time(s); maxRetries=45
2017-03-08 23:32:28,406 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 30 time(s); maxRetries=45
2017-03-08 23:32:48,424 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 31 time(s); maxRetries=45
2017-03-08 23:33:08,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 32 time(s); maxRetries=45
2017-03-08 23:33:28,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 33 time(s); maxRetries=45
2017-03-08 23:33:48,447 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 34 time(s); maxRetries=45
2017-03-08 23:34:08,461 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 35 time(s); maxRetries=45
2017-03-08 23:34:28,471 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 36 time(s); maxRetries=45
2017-03-08 23:34:48,474 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 37 time(s); maxRetries=45
2017-03-08 23:35:08,478 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 38 time(s); maxRetries=45
2017-03-08 23:35:28,495 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 39 time(s); maxRetries=45
2017-03-08 23:35:48,510 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 40 time(s); maxRetries=45
2017-03-08 23:36:08,526 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 41 time(s); maxRetries=45
2017-03-08 23:36:28,547 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 42 time(s); maxRetries=45
2017-03-08 23:36:48,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 43 time(s); maxRetries=45
2017-03-08 23:37:08,580 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 44 time(s); maxRetries=45
2017-03-08 23:38:18,623 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-08 23:38:18,624 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); maxRetries=45
2017-03-08 23:38:38,645 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); maxRetries=45
2017-03-08 23:38:58,662 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); maxRetries=45
2017-03-08 23:39:18,673 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); maxRetries=45
2017-03-08 23:39:38,675 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); maxRetries=45
2017-03-08 23:39:58,691 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); maxRetries=45
2017-03-08 23:40:18,709 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); maxRetries=45
2017-03-08 23:40:38,717 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); maxRetries=45
2017-03-08 23:40:58,734 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); maxRetries=45
2017-03-08 23:41:18,746 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); maxRetries=45
2017-03-08 23:41:38,767 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 10 time(s); maxRetries=45
2017-03-08 23:41:58,788 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 11 time(s); maxRetries=45
2017-03-08 23:42:18,809 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 12 time(s); maxRetries=45
2017-03-08 23:42:38,817 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 13 time(s); maxRetries=45
2017-03-08 23:42:58,833 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 14 time(s); maxRetries=45
2017-03-08 23:43:18,836 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 15 time(s); maxRetries=45
2017-03-08 23:43:38,850 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 16 time(s); maxRetries=45
2017-03-08 23:43:58,861 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 17 time(s); maxRetries=45
2017-03-08 23:44:18,871 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 18 time(s); maxRetries=45
2017-03-08 23:44:38,892 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 19 time(s); maxRetries=45
2017-03-08 23:44:58,913 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 20 time(s); maxRetries=45
2017-03-08 23:45:18,934 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 21 time(s); maxRetries=45
2017-03-08 23:45:38,955 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 22 time(s); maxRetries=45
2017-03-08 23:45:58,973 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 23 time(s); maxRetries=45
2017-03-08 23:46:18,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 24 time(s); maxRetries=45
2017-03-08 23:46:39,014 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 25 time(s); maxRetries=45
2017-03-08 23:46:59,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 26 time(s); maxRetries=45
2017-03-08 23:47:19,047 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 27 time(s); maxRetries=45
2017-03-08 23:47:39,069 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 28 time(s); maxRetries=45
2017-03-08 23:47:59,075 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 29 time(s); maxRetries=45
2017-03-08 23:48:19,096 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 30 time(s); maxRetries=45
2017-03-08 23:48:39,116 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 31 time(s); maxRetries=45
2017-03-08 23:48:59,121 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 32 time(s); maxRetries=45
2017-03-08 23:49:19,138 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 33 time(s); maxRetries=45
2017-03-08 23:49:39,154 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 34 time(s); maxRetries=45
2017-03-08 23:49:59,166 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 35 time(s); maxRetries=45
2017-03-08 23:50:19,187 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 36 time(s); maxRetries=45
2017-03-08 23:50:39,208 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 37 time(s); maxRetries=45
2017-03-08 23:50:59,226 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 38 time(s); maxRetries=45
2017-03-08 23:51:19,235 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 39 time(s); maxRetries=45
2017-03-08 23:51:39,252 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 40 time(s); maxRetries=45
2017-03-08 23:51:59,273 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 41 time(s); maxRetries=45
2017-03-08 23:52:19,294 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 42 time(s); maxRetries=45
2017-03-08 23:52:39,298 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 43 time(s); maxRetries=45
2017-03-08 23:52:59,310 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 44 time(s); maxRetries=45
2017-03-08 23:54:09,343 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-08 23:54:09,343 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); maxRetries=45
2017-03-08 23:54:29,363 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); maxRetries=45
2017-03-08 23:54:49,382 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); maxRetries=45
2017-03-08 23:55:09,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); maxRetries=45
2017-03-08 23:55:29,424 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); maxRetries=45
2017-03-08 23:55:49,443 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); maxRetries=45
2017-03-08 23:56:09,464 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); maxRetries=45
2017-03-08 23:56:29,483 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); maxRetries=45
2017-03-08 23:56:49,495 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); maxRetries=45
2017-03-08 23:57:09,516 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); maxRetries=45
2017-03-08 23:57:29,538 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 10 time(s); maxRetries=45
2017-03-08 23:57:49,539 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 11 time(s); maxRetries=45
2017-03-08 23:58:09,556 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 12 time(s); maxRetries=45
2017-03-08 23:58:29,577 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 13 time(s); maxRetries=45
2017-03-08 23:58:49,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 14 time(s); maxRetries=45
2017-03-08 23:59:09,608 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 15 time(s); maxRetries=45
2017-03-08 23:59:29,629 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 16 time(s); maxRetries=45
2017-03-08 23:59:49,645 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 17 time(s); maxRetries=45
2017-03-09 00:00:09,666 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 18 time(s); maxRetries=45
2017-03-09 00:00:29,687 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 19 time(s); maxRetries=45
2017-03-09 00:00:49,698 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 20 time(s); maxRetries=45
2017-03-09 00:01:09,708 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 21 time(s); maxRetries=45
2017-03-09 00:01:29,718 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 22 time(s); maxRetries=45
2017-03-09 00:01:49,731 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 23 time(s); maxRetries=45
2017-03-09 00:02:09,738 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 24 time(s); maxRetries=45
2017-03-09 00:02:29,759 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 25 time(s); maxRetries=45
2017-03-09 00:02:49,780 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 26 time(s); maxRetries=45
2017-03-09 00:03:09,790 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 27 time(s); maxRetries=45
2017-03-09 00:03:29,800 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 28 time(s); maxRetries=45
2017-03-09 00:03:49,821 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 29 time(s); maxRetries=45
2017-03-09 00:04:09,842 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 30 time(s); maxRetries=45
2017-03-09 00:04:29,863 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 31 time(s); maxRetries=45
2017-03-09 00:04:49,871 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 32 time(s); maxRetries=45
2017-03-09 00:05:09,881 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 33 time(s); maxRetries=45
2017-03-09 00:05:29,900 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 34 time(s); maxRetries=45
2017-03-09 00:05:49,918 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 35 time(s); maxRetries=45
2017-03-09 00:06:09,939 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 36 time(s); maxRetries=45
2017-03-09 00:06:29,946 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 37 time(s); maxRetries=45
2017-03-09 00:06:49,960 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 38 time(s); maxRetries=45
2017-03-09 00:07:09,977 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 39 time(s); maxRetries=45
2017-03-09 00:07:29,995 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 40 time(s); maxRetries=45
2017-03-09 00:07:50,016 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 41 time(s); maxRetries=45
2017-03-09 00:08:10,028 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 42 time(s); maxRetries=45
2017-03-09 00:08:30,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 43 time(s); maxRetries=45
2017-03-09 00:08:50,045 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 44 time(s); maxRetries=45
2017-03-09 00:10:00,060 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 00:10:00,060 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); maxRetries=45
2017-03-09 00:10:20,081 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); maxRetries=45
2017-03-09 00:10:40,102 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); maxRetries=45
2017-03-09 00:11:00,118 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); maxRetries=45
2017-03-09 00:11:20,138 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); maxRetries=45
2017-03-09 00:11:40,158 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); maxRetries=45
2017-03-09 00:12:00,178 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); maxRetries=45
2017-03-09 00:12:20,196 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); maxRetries=45
2017-03-09 00:12:40,217 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); maxRetries=45
2017-03-09 00:13:00,237 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); maxRetries=45
2017-03-09 12:40:01,740 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 10 time(s); maxRetries=45
2017-03-09 12:40:21,745 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 11 time(s); maxRetries=45
2017-03-09 12:40:22,746 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:40:23,746 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:40:24,747 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:40:25,748 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:40:26,748 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:40:27,749 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:40:28,750 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:40:29,750 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:40:30,751 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:40:31,752 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:41:01,755 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 12:41:02,755 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:41:03,756 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:41:04,756 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:41:05,757 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:41:06,758 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:41:07,758 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:41:08,759 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:41:09,760 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:41:10,761 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:41:11,762 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:41:41,764 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 12:41:42,764 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:41:43,765 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:41:44,766 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:41:45,766 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:41:46,767 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:41:47,768 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:41:48,769 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:41:49,769 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:41:50,770 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:41:51,771 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:42:21,774 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 12:42:22,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:42:23,775 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:42:24,776 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:42:25,776 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:42:26,777 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:42:27,778 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:42:28,779 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:42:29,780 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:42:30,780 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:42:31,781 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:43:01,784 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 12:43:02,784 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:43:03,785 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:43:04,786 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:43:05,787 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:43:06,787 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:43:07,788 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:43:08,789 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:43:09,790 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:43:10,790 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:43:11,791 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:43:41,794 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 12:43:42,795 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:43:43,795 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:43:44,796 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:43:45,797 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:43:46,798 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:43:47,799 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:43:48,799 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:43:49,800 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:43:50,801 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:43:51,802 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:44:21,805 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 12:44:22,805 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:44:23,806 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:44:24,806 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:44:25,807 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:44:26,807 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:44:27,808 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:44:28,809 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:44:29,809 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:44:30,810 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:44:31,811 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:45:02,948 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 12:45:03,948 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:45:04,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:45:05,950 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:45:06,950 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:45:07,950 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:45:08,951 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:45:09,952 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:45:10,953 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:45:11,954 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:45:12,954 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:45:42,996 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 12:45:43,997 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:45:44,997 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:45:45,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:45:46,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:45:47,999 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:45:49,000 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:45:50,001 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:45:51,002 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:45:52,003 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:45:53,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:46:23,012 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 12:46:24,012 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:46:25,013 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:46:26,013 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:46:27,014 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:46:28,014 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:46:29,015 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:46:30,016 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:46:31,017 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:46:32,018 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:46:33,019 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:47:03,026 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 12:47:04,026 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:47:05,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:47:06,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:47:07,028 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:47:08,028 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:47:09,029 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:47:10,029 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:47:11,030 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:47:12,030 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:47:13,031 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:47:43,037 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 12:47:44,038 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:47:45,039 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:47:46,040 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:47:47,041 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:47:48,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:47:49,043 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:47:50,044 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:47:51,045 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:47:52,046 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:47:53,047 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:48:23,053 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 12:48:24,054 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:48:25,055 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:48:26,056 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:48:27,057 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:48:28,058 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:48:29,058 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:48:30,059 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:48:31,059 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:48:32,060 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:48:33,060 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:49:03,078 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 12:49:04,078 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:49:05,079 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:49:06,080 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:49:07,081 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:49:08,082 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:49:09,082 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:49:10,083 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:49:11,084 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:49:12,084 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:49:13,086 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:49:43,103 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 12:49:44,104 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:49:45,104 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:49:46,105 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:49:47,106 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:49:48,107 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:49:49,107 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:49:50,108 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:49:51,109 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:49:52,109 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:49:53,110 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:50:23,118 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 12:50:24,119 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:50:25,120 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:50:26,121 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:50:27,122 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:50:28,123 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:50:29,125 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:50:30,125 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:50:31,126 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:50:32,127 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:50:33,128 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 12:50:33,180 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-09 12:50:33,281 INFO org.apache.hadoop.ipc.Server: Stopping server on 54524
2017-03-09 12:50:33,284 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-09 12:50:33,284 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl is interrupted. Exiting.
2017-03-09 12:50:33,288 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 54524
2017-03-09 12:50:33,347 INFO org.apache.hadoop.ipc.Server: Stopping server on 8040
2017-03-09 12:50:33,347 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8040
2017-03-09 12:50:33,348 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-09 12:50:33,348 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Public cache exiting
2017-03-09 12:50:33,348 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NodeManager metrics system...
2017-03-09 12:50:33,348 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system stopped.
2017-03-09 12:50:33,349 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system shutdown complete.
2017-03-09 12:50:33,368 INFO org.apache.hadoop.util.ExitUtil: Exiting with status -1
2017-03-09 12:50:33,369 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NodeManager at gaurav-Inspiron-3542/127.0.1.1
************************************************************/
2017-03-09 12:52:05,907 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = gaurav-Inspiron-3542/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-digester-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsch-0.1.42.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-net-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.7.0_111
************************************************************/
2017-03-09 12:52:05,915 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2017-03-09 12:52:07,137 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2017-03-09 12:52:07,139 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2017-03-09 12:52:07,140 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2017-03-09 12:52:07,140 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2017-03-09 12:52:07,141 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2017-03-09 12:52:07,142 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2017-03-09 12:52:07,174 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2017-03-09 12:52:07,174 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2017-03-09 12:52:07,224 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-03-09 12:52:07,306 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-03-09 12:52:07,306 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2017-03-09 12:52:07,386 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2017-03-09 12:52:07,388 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2017-03-09 12:52:07,388 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2017-03-09 12:52:07,429 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/tmp/hadoop-hadoop/nm-local-dir/usercache_DEL_1489044127392
2017-03-09 12:52:07,491 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2017-03-09 12:52:07,536 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2017-03-09 12:52:07,536 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2017-03-09 12:52:07,598 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@5599a2ab
2017-03-09 12:52:07,598 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2017-03-09 12:52:07,598 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2017-03-09 12:52:07,598 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2017-03-09 12:52:07,601 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (3.8 G). Thrashing might happen.
2017-03-09 12:52:07,605 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2017-03-09 12:52:07,765 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-09 12:52:07,789 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50868
2017-03-09 12:52:07,852 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2017-03-09 12:52:07,852 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2017-03-09 12:52:07,852 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-09 12:52:07,852 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50868: starting
2017-03-09 12:52:07,858 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : gaurav-Inspiron-3542:50868
2017-03-09 12:52:07,868 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-09 12:52:07,868 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2017-03-09 12:52:07,871 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2017-03-09 12:52:07,872 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-09 12:52:07,882 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2017-03-09 12:52:07,881 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2017-03-09 12:52:07,893 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2017-03-09 12:52:07,903 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2017-03-09 12:52:07,905 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at gaurav-Inspiron-3542/127.0.1.1:50868
2017-03-09 12:52:07,905 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2017-03-09 12:52:07,906 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2017-03-09 12:52:07,977 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-03-09 12:52:07,986 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-03-09 12:52:07,990 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2017-03-09 12:52:07,997 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-03-09 12:52:08,000 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2017-03-09 12:52:08,001 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-03-09 12:52:08,001 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-03-09 12:52:08,004 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /node/*
2017-03-09 12:52:08,004 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2017-03-09 12:52:08,325 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2017-03-09 12:52:08,327 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2017-03-09 12:52:08,327 INFO org.mortbay.log: jetty-6.1.26
2017-03-09 12:52:08,364 INFO org.mortbay.log: Extract jar:file:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2017-03-09 12:52:09,445 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-09 12:52:09,445 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2017-03-09 12:52:09,450 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /192.168.43.107:8025
2017-03-09 12:52:09,470 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out 0 NM container statuses: []
2017-03-09 12:52:09,475 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registering with RM using containers :[]
2017-03-09 12:52:11,033 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 298958071
2017-03-09 12:52:11,037 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id 863986148
2017-03-09 12:52:11,038 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as gaurav-Inspiron-3542:50868 with total resource of <memory:8192, vCores:8>
2017-03-09 12:52:11,039 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2017-03-09 12:53:06,725 ERROR org.apache.hadoop.yarn.server.nodemanager.NodeManager: RECEIVED SIGNAL 15: SIGTERM
2017-03-09 12:53:06,739 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-09 12:53:06,839 INFO org.apache.hadoop.ipc.Server: Stopping server on 50868
2017-03-09 12:53:06,840 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 50868
2017-03-09 12:53:06,840 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-09 12:53:06,840 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl is interrupted. Exiting.
2017-03-09 12:53:06,853 INFO org.apache.hadoop.ipc.Server: Stopping server on 8040
2017-03-09 12:53:06,853 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8040
2017-03-09 12:53:06,854 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-09 12:53:06,854 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Public cache exiting
2017-03-09 12:53:06,854 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NodeManager metrics system...
2017-03-09 12:53:06,855 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system stopped.
2017-03-09 12:53:06,855 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system shutdown complete.
2017-03-09 12:53:06,855 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NodeManager at gaurav-Inspiron-3542/127.0.1.1
************************************************************/
2017-03-09 12:57:24,612 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = gaurav-Inspiron-3542/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-digester-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsch-0.1.42.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-net-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.7.0_111
************************************************************/
2017-03-09 12:57:24,623 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2017-03-09 12:57:25,703 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2017-03-09 12:57:25,705 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2017-03-09 12:57:25,706 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2017-03-09 12:57:25,707 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2017-03-09 12:57:25,707 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2017-03-09 12:57:25,708 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2017-03-09 12:57:25,742 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2017-03-09 12:57:25,743 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2017-03-09 12:57:25,780 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-03-09 12:57:25,851 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-03-09 12:57:25,851 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2017-03-09 12:57:25,875 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2017-03-09 12:57:25,877 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2017-03-09 12:57:25,877 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2017-03-09 12:57:25,903 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/tmp/hadoop-hadoop/nm-local-dir/usercache_DEL_1489044445881
2017-03-09 12:57:25,964 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2017-03-09 12:57:25,989 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2017-03-09 12:57:25,989 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2017-03-09 12:57:26,027 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@1db0a9f9
2017-03-09 12:57:26,028 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2017-03-09 12:57:26,028 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2017-03-09 12:57:26,028 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2017-03-09 12:57:26,033 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (3.8 G). Thrashing might happen.
2017-03-09 12:57:26,040 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2017-03-09 12:57:26,079 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-09 12:57:26,097 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 35207
2017-03-09 12:57:26,152 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2017-03-09 12:57:26,152 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2017-03-09 12:57:26,153 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-09 12:57:26,153 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 35207: starting
2017-03-09 12:57:26,161 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : gaurav-Inspiron-3542:35207
2017-03-09 12:57:26,170 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-09 12:57:26,171 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2017-03-09 12:57:26,174 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2017-03-09 12:57:26,175 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-09 12:57:26,175 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2017-03-09 12:57:26,175 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2017-03-09 12:57:26,188 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2017-03-09 12:57:26,199 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2017-03-09 12:57:26,202 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at gaurav-Inspiron-3542/127.0.1.1:35207
2017-03-09 12:57:26,202 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2017-03-09 12:57:26,203 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2017-03-09 12:57:26,274 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-03-09 12:57:26,286 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-03-09 12:57:26,292 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2017-03-09 12:57:26,299 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-03-09 12:57:26,301 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2017-03-09 12:57:26,301 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-03-09 12:57:26,301 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-03-09 12:57:26,304 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /node/*
2017-03-09 12:57:26,304 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2017-03-09 12:57:26,629 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2017-03-09 12:57:26,631 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2017-03-09 12:57:26,631 INFO org.mortbay.log: jetty-6.1.26
2017-03-09 12:57:26,651 INFO org.mortbay.log: Extract jar:file:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2017-03-09 12:57:27,601 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-09 12:57:27,602 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2017-03-09 12:57:27,607 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /192.168.43.107:8025
2017-03-09 12:57:27,627 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out 0 NM container statuses: []
2017-03-09 12:57:27,631 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registering with RM using containers :[]
2017-03-09 12:57:29,003 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id -914377561
2017-03-09 12:57:29,008 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id -535321462
2017-03-09 12:57:29,009 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as gaurav-Inspiron-3542:35207 with total resource of <memory:8192, vCores:8>
2017-03-09 12:57:29,009 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2017-03-09 13:09:58,236 ERROR org.apache.hadoop.yarn.server.nodemanager.NodeManager: RECEIVED SIGNAL 15: SIGTERM
2017-03-09 13:09:58,240 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-09 13:09:58,341 INFO org.apache.hadoop.ipc.Server: Stopping server on 35207
2017-03-09 13:09:58,342 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 35207
2017-03-09 13:09:58,345 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl is interrupted. Exiting.
2017-03-09 13:09:58,346 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-09 13:09:58,352 INFO org.apache.hadoop.ipc.Server: Stopping server on 8040
2017-03-09 13:09:58,352 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8040
2017-03-09 13:09:58,352 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-09 13:09:58,353 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Public cache exiting
2017-03-09 13:09:58,353 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NodeManager metrics system...
2017-03-09 13:09:58,354 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system stopped.
2017-03-09 13:09:58,354 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system shutdown complete.
2017-03-09 13:09:58,354 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NodeManager at gaurav-Inspiron-3542/127.0.1.1
************************************************************/
2017-03-09 13:12:56,386 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = gaurav-Inspiron-3542/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-digester-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsch-0.1.42.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-net-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.7.0_111
************************************************************/
2017-03-09 13:12:56,394 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2017-03-09 13:12:57,488 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2017-03-09 13:12:57,489 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2017-03-09 13:12:57,490 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2017-03-09 13:12:57,491 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2017-03-09 13:12:57,491 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2017-03-09 13:12:57,492 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2017-03-09 13:12:57,524 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2017-03-09 13:12:57,524 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2017-03-09 13:12:57,561 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-03-09 13:12:57,631 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-03-09 13:12:57,631 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2017-03-09 13:12:57,657 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2017-03-09 13:12:57,658 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2017-03-09 13:12:57,659 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2017-03-09 13:12:57,681 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/tmp/hadoop-hadoop/nm-local-dir/usercache_DEL_1489045377662
2017-03-09 13:12:57,731 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2017-03-09 13:12:57,757 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2017-03-09 13:12:57,757 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2017-03-09 13:12:57,797 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@5599a2ab
2017-03-09 13:12:57,797 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2017-03-09 13:12:57,798 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2017-03-09 13:12:57,798 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2017-03-09 13:12:57,802 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (3.8 G). Thrashing might happen.
2017-03-09 13:12:57,806 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2017-03-09 13:12:57,842 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-09 13:12:57,860 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 53083
2017-03-09 13:12:57,911 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2017-03-09 13:12:57,911 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2017-03-09 13:12:57,912 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-09 13:12:57,913 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 53083: starting
2017-03-09 13:12:57,921 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : gaurav-Inspiron-3542:53083
2017-03-09 13:12:57,930 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-09 13:12:57,930 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2017-03-09 13:12:57,933 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2017-03-09 13:12:57,934 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-09 13:12:57,934 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2017-03-09 13:12:57,934 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2017-03-09 13:12:57,948 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2017-03-09 13:12:57,960 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2017-03-09 13:12:57,962 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at gaurav-Inspiron-3542/127.0.1.1:53083
2017-03-09 13:12:57,963 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2017-03-09 13:12:57,964 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2017-03-09 13:12:58,035 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-03-09 13:12:58,044 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-03-09 13:12:58,049 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2017-03-09 13:12:58,056 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-03-09 13:12:58,059 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2017-03-09 13:12:58,059 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-03-09 13:12:58,059 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-03-09 13:12:58,062 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /node/*
2017-03-09 13:12:58,062 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2017-03-09 13:12:58,390 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2017-03-09 13:12:58,392 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2017-03-09 13:12:58,392 INFO org.mortbay.log: jetty-6.1.26
2017-03-09 13:12:58,416 INFO org.mortbay.log: Extract jar:file:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2017-03-09 13:12:59,335 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-09 13:12:59,335 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2017-03-09 13:12:59,341 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /192.168.43.107:8025
2017-03-09 13:12:59,361 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out 0 NM container statuses: []
2017-03-09 13:12:59,365 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registering with RM using containers :[]
2017-03-09 13:13:00,534 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 2081494063
2017-03-09 13:13:00,536 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id -776267471
2017-03-09 13:13:00,537 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as gaurav-Inspiron-3542:53083 with total resource of <memory:8192, vCores:8>
2017-03-09 13:13:00,537 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2017-03-09 13:26:46,782 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 13:26:47,783 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:26:48,784 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:26:49,785 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:26:50,786 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:26:51,787 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:26:52,788 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:26:53,788 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:26:54,789 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:26:55,790 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:26:56,791 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:27:29,794 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 13:27:30,795 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:27:31,796 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:27:32,797 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:27:33,798 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:27:34,799 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:27:35,800 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:27:36,801 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:27:37,802 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:27:38,803 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:27:39,804 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:28:12,806 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 13:28:13,807 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:28:14,808 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:28:15,808 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:28:16,809 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:28:17,810 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:28:18,811 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:28:19,812 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:28:20,813 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:28:21,814 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:28:22,815 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:28:55,818 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 13:28:56,819 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:28:57,820 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:28:58,821 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:28:59,822 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:29:00,822 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:29:01,823 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:29:02,824 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:29:03,824 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:29:04,825 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:29:05,826 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:29:38,826 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 13:29:39,827 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:29:40,828 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:29:41,829 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:29:42,830 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:29:43,831 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:29:44,832 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:29:45,833 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:29:46,834 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:29:47,834 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:29:48,835 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:30:21,838 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 13:30:22,839 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:30:23,840 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:30:24,841 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:30:25,842 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:30:26,843 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:30:27,844 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:30:28,845 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:30:29,846 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:30:30,847 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:30:31,848 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:31:04,850 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 13:31:05,851 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:31:06,852 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:31:07,853 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:31:08,854 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:31:09,855 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:31:10,856 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:31:11,857 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:31:12,858 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:31:13,859 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:31:14,860 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:31:47,862 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 13:31:48,862 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:31:49,863 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:31:50,864 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:31:51,864 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:31:52,865 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:31:53,866 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:31:54,867 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:31:55,868 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:31:56,868 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:31:57,869 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:32:30,870 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 13:32:31,870 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:32:32,870 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:32:33,871 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:32:34,872 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:32:35,872 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:32:36,873 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:32:37,874 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:32:38,874 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:32:39,875 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:32:40,876 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:33:13,878 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 13:33:14,879 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:33:15,880 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:33:16,881 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:33:17,881 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:33:18,882 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:33:19,883 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:33:20,883 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:33:21,884 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:33:22,885 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:33:23,886 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:33:56,886 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 13:33:57,887 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:33:58,888 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:33:59,889 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:34:00,889 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:34:01,890 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:34:02,892 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:34:03,893 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:34:04,893 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:34:05,894 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:34:06,894 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:34:39,894 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 13:34:40,894 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:34:41,894 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:34:42,895 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:34:43,895 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:34:44,896 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:34:45,897 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:34:46,897 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:34:47,898 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:34:48,898 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:34:49,899 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:35:22,898 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 13:35:23,898 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:35:24,899 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:35:25,899 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:35:26,900 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:35:27,901 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:35:28,902 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:35:29,903 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:35:30,903 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:35:31,904 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:35:32,904 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:36:05,906 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 13:36:06,907 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:36:07,908 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:36:08,909 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:36:09,910 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:36:10,911 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:36:11,912 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:36:12,913 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:36:13,914 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:36:14,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:36:15,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:36:48,914 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 13:36:49,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:36:50,916 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:36:51,917 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:36:52,917 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:36:53,918 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:36:54,918 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:36:55,919 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:36:56,919 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:36:57,920 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:36:58,922 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:37:31,922 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 13:37:32,922 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:37:33,924 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:37:34,924 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:37:35,925 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:37:36,926 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:37:37,928 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:37:38,928 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:37:39,929 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:37:40,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:37:41,931 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:38:14,934 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 13:38:15,935 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:38:16,935 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:38:17,937 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:38:18,938 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:38:19,939 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:38:20,940 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:38:21,940 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:38:22,941 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:38:23,942 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:38:24,943 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:38:57,946 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 13:38:58,946 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:38:59,947 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:39:00,948 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:39:01,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:39:02,950 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:39:03,951 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:39:04,952 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:39:05,953 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:39:06,955 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:39:07,956 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:39:40,958 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 13:39:41,958 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:39:42,960 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:39:43,961 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:39:44,962 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:39:45,963 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:39:46,964 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:39:47,965 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:39:48,967 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:39:49,968 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:39:50,969 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:40:23,974 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 13:40:24,975 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:40:25,976 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:40:26,977 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:40:27,978 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:40:28,979 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:40:29,980 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:40:30,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:40:31,982 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:40:32,983 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:40:33,984 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:41:06,986 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 13:41:07,987 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:41:08,988 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:41:09,989 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:41:10,990 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:41:11,991 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:41:12,992 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:41:13,993 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:41:14,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:41:15,995 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:41:16,996 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:41:49,994 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 13:41:50,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:41:51,995 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:41:52,996 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:41:53,997 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:41:54,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:41:56,000 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:41:57,001 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:41:58,002 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:41:59,003 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:42:00,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:42:33,006 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 13:42:34,006 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:42:35,006 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:42:36,007 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:42:37,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:42:38,010 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:42:39,010 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:42:40,011 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:42:41,012 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:42:42,013 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:42:43,014 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:43:16,014 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 13:43:17,015 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:43:18,016 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:43:19,017 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:43:20,018 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:43:21,019 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:43:22,020 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:43:23,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:43:24,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:43:25,022 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:43:26,023 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:43:59,026 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 13:44:00,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:44:01,028 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:44:02,029 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:44:03,030 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:44:04,031 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:44:05,032 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:44:06,033 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:44:07,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:44:08,035 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:44:09,035 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:44:42,038 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 13:44:43,039 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:44:44,040 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:44:45,041 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:44:46,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:44:47,043 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:44:48,044 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:44:49,045 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:44:50,046 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:44:51,046 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:44:52,047 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:45:25,050 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 13:45:26,051 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:45:27,051 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:45:28,052 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:45:29,053 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:45:30,054 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:45:31,055 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:45:32,056 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:45:33,057 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:45:34,058 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:45:35,059 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:46:08,062 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 13:46:09,062 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:46:10,063 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:46:11,064 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:46:12,065 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:46:13,067 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:46:14,068 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:46:15,069 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:46:16,070 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:46:17,071 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:46:18,072 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:46:51,074 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 13:46:52,074 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:46:53,075 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:46:54,075 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:46:55,076 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:46:56,077 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:46:57,078 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:46:58,079 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:46:59,080 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:47:00,081 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:47:01,082 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:47:34,082 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 13:47:35,083 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:47:36,084 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:47:37,084 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:47:38,085 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:47:39,086 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:47:40,087 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:47:41,088 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:47:42,089 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:47:43,091 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:47:44,092 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 13:47:44,131 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-09 13:47:44,232 INFO org.apache.hadoop.ipc.Server: Stopping server on 53083
2017-03-09 13:47:44,233 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-09 13:47:44,233 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 53083
2017-03-09 13:47:44,233 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl is interrupted. Exiting.
2017-03-09 13:47:44,239 INFO org.apache.hadoop.ipc.Server: Stopping server on 8040
2017-03-09 13:47:44,239 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8040
2017-03-09 13:47:44,239 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-09 13:47:44,240 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Public cache exiting
2017-03-09 13:47:44,244 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NodeManager metrics system...
2017-03-09 13:47:44,245 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system stopped.
2017-03-09 13:47:44,245 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system shutdown complete.
2017-03-09 13:47:44,246 INFO org.apache.hadoop.util.ExitUtil: Exiting with status -1
2017-03-09 13:47:44,247 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NodeManager at gaurav-Inspiron-3542/127.0.1.1
************************************************************/
2017-03-09 14:12:04,478 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = gaurav-Inspiron-3542/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-digester-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsch-0.1.42.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-net-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.7.0_111
************************************************************/
2017-03-09 14:12:04,490 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2017-03-09 14:12:05,608 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2017-03-09 14:12:05,609 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2017-03-09 14:12:05,610 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2017-03-09 14:12:05,611 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2017-03-09 14:12:05,611 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2017-03-09 14:12:05,612 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2017-03-09 14:12:05,644 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2017-03-09 14:12:05,645 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2017-03-09 14:12:05,692 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-03-09 14:12:05,773 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-03-09 14:12:05,773 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2017-03-09 14:12:05,803 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2017-03-09 14:12:05,805 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2017-03-09 14:12:05,805 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2017-03-09 14:12:05,831 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/tmp/hadoop-hadoop/nm-local-dir/usercache_DEL_1489048925808
2017-03-09 14:12:05,903 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2017-03-09 14:12:05,929 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2017-03-09 14:12:05,929 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2017-03-09 14:12:05,973 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@45f74db7
2017-03-09 14:12:05,973 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2017-03-09 14:12:05,973 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2017-03-09 14:12:05,973 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2017-03-09 14:12:05,978 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (3.8 G). Thrashing might happen.
2017-03-09 14:12:05,984 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2017-03-09 14:12:16,066 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-09 14:12:16,098 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 52841
2017-03-09 14:12:16,142 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2017-03-09 14:12:16,142 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2017-03-09 14:12:16,143 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-09 14:12:16,143 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 52841: starting
2017-03-09 14:12:16,149 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : gaurav-Inspiron-3542:52841
2017-03-09 14:12:26,167 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-09 14:12:26,168 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2017-03-09 14:12:26,178 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2017-03-09 14:12:26,179 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2017-03-09 14:12:26,180 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-09 14:12:26,183 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2017-03-09 14:12:26,210 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2017-03-09 14:12:26,232 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2017-03-09 14:12:26,236 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at gaurav-Inspiron-3542/127.0.1.1:52841
2017-03-09 14:12:26,236 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2017-03-09 14:12:26,238 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2017-03-09 14:12:26,307 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-03-09 14:12:26,319 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-03-09 14:12:26,326 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2017-03-09 14:12:26,336 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-03-09 14:12:26,339 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2017-03-09 14:12:26,340 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-03-09 14:12:26,340 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-03-09 14:12:26,344 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /node/*
2017-03-09 14:12:26,344 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2017-03-09 14:12:26,690 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2017-03-09 14:12:26,692 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2017-03-09 14:12:26,692 INFO org.mortbay.log: jetty-6.1.26
2017-03-09 14:12:26,714 INFO org.mortbay.log: Extract jar:file:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2017-03-09 14:12:27,790 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-09 14:12:27,790 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2017-03-09 14:12:27,796 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /192.168.43.107:8025
2017-03-09 14:12:27,816 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out 0 NM container statuses: []
2017-03-09 14:12:27,820 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registering with RM using containers :[]
2017-03-09 14:12:29,076 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id -809865384
2017-03-09 14:12:29,083 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id -1580126796
2017-03-09 14:12:29,084 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as gaurav-Inspiron-3542:52841 with total resource of <memory:8192, vCores:8>
2017-03-09 14:12:29,084 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2017-03-09 14:30:41,254 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 14:30:42,255 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:30:43,256 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:30:44,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:30:45,259 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:30:46,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:30:47,261 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:30:48,262 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:30:49,263 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:30:50,263 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:30:51,265 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:31:24,266 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 14:31:25,267 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:31:26,268 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:31:27,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:31:28,270 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:31:29,271 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:31:30,272 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:31:31,273 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:31:32,274 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:31:33,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:31:34,276 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:32:07,278 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 14:32:08,279 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:32:09,280 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:32:10,281 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:32:11,282 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:32:12,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:32:13,284 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:32:14,285 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:32:15,286 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:32:16,287 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:32:17,288 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:32:50,290 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 14:32:51,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:32:52,291 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:32:53,292 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:32:54,293 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:32:55,294 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:32:56,296 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:32:57,297 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:32:58,298 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:32:59,299 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:33:00,300 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:33:33,302 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 14:33:34,303 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:33:35,304 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:33:36,305 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:33:37,306 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:33:38,307 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:33:39,308 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:33:40,309 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:33:41,310 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:33:42,311 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:33:43,312 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:34:16,314 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 14:34:17,314 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:34:18,315 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:34:19,315 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:34:20,316 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:34:21,316 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:34:22,318 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:34:23,319 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:34:24,320 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:34:25,321 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:34:26,322 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:34:59,322 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 14:35:00,322 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:35:01,323 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:35:02,323 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:35:03,324 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:35:04,325 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:35:05,326 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:35:06,327 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:35:07,327 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:35:08,328 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:35:09,328 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:35:42,330 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 14:35:43,330 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:35:44,331 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:35:45,332 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:35:46,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:35:47,334 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:35:48,335 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:35:49,336 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:35:50,337 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:35:51,338 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:35:52,339 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:36:25,338 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 14:36:26,338 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:36:27,339 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:36:28,339 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:36:29,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:36:30,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:36:31,341 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:36:32,342 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:36:33,343 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:36:34,344 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:36:35,345 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:37:08,346 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 14:37:09,346 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:37:10,347 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:37:11,349 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:37:12,350 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:37:13,351 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:37:14,352 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:37:15,353 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:37:16,354 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:37:17,355 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:37:18,355 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:37:51,354 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 14:37:52,354 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:37:53,355 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:37:54,356 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:37:55,357 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:37:56,358 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:37:57,359 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:37:58,360 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:37:59,361 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:38:00,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:38:01,363 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:38:34,366 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 14:38:35,367 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:38:36,368 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:38:37,368 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:38:38,369 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:38:39,369 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:38:40,370 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:38:41,370 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:38:42,372 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:38:43,372 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:38:44,373 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:39:17,374 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 14:39:18,375 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:39:19,376 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:39:20,376 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:39:21,377 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:39:22,378 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:39:23,379 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:39:24,379 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:39:25,380 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:39:26,381 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:39:27,381 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:40:00,386 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 14:40:01,386 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:40:02,386 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:40:03,387 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:40:04,388 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:40:05,388 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:40:06,389 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:40:07,391 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:40:08,391 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:40:09,392 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:40:10,392 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:40:43,394 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 14:40:44,394 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:40:45,394 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:40:46,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:40:47,396 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:40:48,397 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:40:49,398 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:40:50,399 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:40:51,400 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:40:52,400 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:40:53,401 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:41:26,402 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 14:41:27,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:41:28,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:41:29,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:41:30,405 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:41:31,405 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:41:32,406 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:41:33,407 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:41:34,407 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:41:35,408 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:41:36,409 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:42:09,410 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 14:42:10,410 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:42:11,412 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:42:12,412 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:42:13,413 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:42:14,413 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:42:15,414 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:42:16,414 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:42:17,416 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:42:18,417 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:42:19,418 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:42:52,422 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 14:42:53,422 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:42:54,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:42:55,424 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:42:56,425 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:42:57,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:42:58,429 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:42:59,430 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:43:00,431 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:43:01,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:43:02,433 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:43:35,436 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 14:43:36,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:43:37,437 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:43:38,438 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:43:39,439 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:43:40,440 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:43:41,442 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:43:42,443 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:43:43,443 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:43:44,444 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:43:45,445 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:44:18,446 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 14:44:19,446 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:44:20,447 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:44:21,448 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:44:22,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:44:23,451 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:44:24,452 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:44:25,453 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:44:26,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:44:27,455 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:44:28,458 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:45:01,458 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 14:45:02,458 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:45:03,458 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:45:04,459 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:45:05,461 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:45:06,461 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:45:07,463 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:45:08,463 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:45:09,464 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:45:10,465 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:45:11,465 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:45:44,466 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 14:45:45,466 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:45:46,467 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:45:47,467 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:45:48,468 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:45:49,469 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:45:50,470 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:45:51,471 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:45:52,471 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:45:53,472 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:45:54,473 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:46:27,474 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 14:46:28,475 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:46:29,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:46:30,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:46:31,477 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:46:32,477 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:46:33,478 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:46:34,479 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:46:35,479 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:46:36,480 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:46:37,480 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:47:10,482 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 14:47:11,482 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:47:12,482 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:47:13,483 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:47:14,484 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:47:15,485 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:47:16,486 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:47:17,487 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:47:18,488 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:47:19,489 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:47:20,490 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:47:53,490 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 14:47:54,490 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:47:55,491 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:47:56,491 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:47:57,492 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:47:58,492 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:47:59,493 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:48:00,493 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:48:01,494 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:48:02,494 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:48:03,495 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:48:36,494 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 14:48:37,494 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:48:38,494 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:48:39,495 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:48:40,496 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:48:41,497 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:48:42,498 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:48:43,498 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:48:44,499 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:48:45,500 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:48:46,501 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:49:19,502 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 14:49:20,503 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:49:21,503 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:49:22,504 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:49:23,505 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:49:24,506 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:49:25,507 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:49:26,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:49:27,509 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:49:28,511 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:49:29,512 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:50:02,514 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 14:50:03,514 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:50:04,515 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:50:05,515 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:50:06,516 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:50:07,517 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:50:08,518 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:50:09,519 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:50:10,520 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:50:11,521 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:50:12,522 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:50:45,522 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 14:50:46,522 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:50:47,523 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:50:48,524 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:50:49,525 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:50:50,526 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:50:51,527 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:50:52,528 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:50:53,529 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:50:54,530 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:50:55,531 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:51:28,534 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-09 14:51:29,534 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:51:30,535 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:51:31,536 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:51:32,537 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:51:33,537 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:51:34,539 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:51:35,540 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:51:36,540 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:51:37,541 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:51:38,542 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-09 14:51:38,669 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-09 14:51:38,773 INFO org.apache.hadoop.ipc.Server: Stopping server on 52841
2017-03-09 14:51:38,776 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 52841
2017-03-09 14:51:38,777 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-09 14:51:38,778 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl is interrupted. Exiting.
2017-03-09 14:51:38,888 INFO org.apache.hadoop.ipc.Server: Stopping server on 8040
2017-03-09 14:51:38,893 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8040
2017-03-09 14:51:38,893 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Public cache exiting
2017-03-09 14:51:38,894 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-09 14:51:38,896 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NodeManager metrics system...
2017-03-09 14:51:38,898 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system stopped.
2017-03-09 14:51:38,898 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system shutdown complete.
2017-03-09 14:51:38,916 INFO org.apache.hadoop.util.ExitUtil: Exiting with status -1
2017-03-09 14:51:38,940 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NodeManager at gaurav-Inspiron-3542/127.0.1.1
************************************************************/
2017-03-17 12:35:16,265 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = gaurav-Inspiron-3542/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-digester-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsch-0.1.42.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-net-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.7.0_111
************************************************************/
2017-03-17 12:35:16,312 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2017-03-17 12:35:17,518 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2017-03-17 12:35:17,519 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2017-03-17 12:35:17,535 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2017-03-17 12:35:17,536 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2017-03-17 12:35:17,536 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2017-03-17 12:35:17,537 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2017-03-17 12:35:17,611 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2017-03-17 12:35:17,612 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2017-03-17 12:35:17,656 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-03-17 12:35:17,730 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-03-17 12:35:17,730 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2017-03-17 12:35:17,832 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2017-03-17 12:35:17,834 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2017-03-17 12:35:17,834 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2017-03-17 12:35:17,871 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2017-03-17 12:35:17,953 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2017-03-17 12:35:17,953 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2017-03-17 12:35:18,077 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@79e9f5b1
2017-03-17 12:35:18,078 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2017-03-17 12:35:18,078 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2017-03-17 12:35:18,078 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2017-03-17 12:35:18,102 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (3.8 G). Thrashing might happen.
2017-03-17 12:35:18,135 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2017-03-17 12:35:18,298 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-17 12:35:18,323 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 53686
2017-03-17 12:35:18,417 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2017-03-17 12:35:18,418 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2017-03-17 12:35:18,419 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 53686: starting
2017-03-17 12:35:18,420 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-17 12:35:18,461 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : gaurav-Inspiron-3542:53686
2017-03-17 12:35:18,484 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-17 12:35:18,489 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2017-03-17 12:35:18,490 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2017-03-17 12:35:18,490 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-17 12:35:18,490 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2017-03-17 12:35:18,491 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2017-03-17 12:35:18,566 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2017-03-17 12:35:18,596 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2017-03-17 12:35:18,599 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at gaurav-Inspiron-3542/127.0.1.1:53686
2017-03-17 12:35:18,600 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2017-03-17 12:35:18,605 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2017-03-17 12:35:18,752 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-03-17 12:35:18,773 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-03-17 12:35:18,781 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2017-03-17 12:35:18,795 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-03-17 12:35:18,798 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2017-03-17 12:35:18,798 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-03-17 12:35:18,798 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-03-17 12:35:18,804 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /node/*
2017-03-17 12:35:18,805 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2017-03-17 12:35:19,398 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2017-03-17 12:35:19,401 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2017-03-17 12:35:19,401 INFO org.mortbay.log: jetty-6.1.26
2017-03-17 12:35:19,424 INFO org.mortbay.log: Extract jar:file:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2017-03-17 12:35:20,684 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-17 12:35:20,685 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2017-03-17 12:35:20,707 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /192.168.43.107:8025
2017-03-17 12:35:20,728 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out 0 NM container statuses: []
2017-03-17 12:35:20,740 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registering with RM using containers :[]
2017-03-17 12:35:22,025 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 1713008485
2017-03-17 12:35:22,039 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id -88407432
2017-03-17 12:35:22,040 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as gaurav-Inspiron-3542:53686 with total resource of <memory:8192, vCores:8>
2017-03-17 12:35:22,040 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2017-03-17 16:26:26,866 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-17 16:26:27,867 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:26:28,868 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:26:29,869 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:26:30,870 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:26:31,871 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:26:32,872 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:26:33,872 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:26:34,873 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:26:35,874 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:26:36,875 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:27:09,878 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-17 16:27:10,879 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:27:11,879 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:27:12,880 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:27:13,881 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:27:14,882 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:27:15,883 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:27:16,884 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:27:17,885 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:27:18,886 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:27:19,887 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:27:52,890 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-17 16:27:53,890 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:27:54,892 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:27:55,893 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:27:56,894 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:27:57,894 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:27:58,895 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:27:59,896 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:28:00,897 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:28:01,898 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:28:02,899 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:28:35,902 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-17 16:28:36,903 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:28:37,904 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:28:38,905 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:28:39,906 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:28:40,906 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:28:41,907 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:28:42,908 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:28:43,909 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:28:44,910 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:28:45,911 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:29:18,914 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-17 16:29:19,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:29:20,916 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:29:21,917 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:29:22,918 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:29:23,919 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:29:24,920 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:29:25,921 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:29:26,922 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:29:27,923 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:29:28,924 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:30:01,926 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-17 16:30:02,927 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:30:03,927 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:30:04,928 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:30:05,929 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:30:06,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:30:07,931 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:30:08,931 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:30:09,932 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:30:10,933 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:30:11,934 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:30:44,934 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-17 16:30:45,934 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:30:46,935 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:30:47,936 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:30:48,937 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:30:49,938 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:30:50,939 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:30:51,940 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:30:52,941 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:30:53,942 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:30:54,943 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:31:27,946 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-17 16:31:28,947 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:31:29,947 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:31:30,948 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:31:31,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:31:32,950 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:31:33,951 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:31:34,952 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:31:35,953 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:31:36,954 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:31:37,955 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:32:10,958 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-17 16:32:11,958 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:32:12,958 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:32:13,959 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:32:14,960 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:32:15,961 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:32:16,962 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:32:17,963 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:32:18,964 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:32:19,965 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:32:20,966 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:32:53,966 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-17 16:32:54,966 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:32:55,966 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:32:56,967 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:32:57,967 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:32:58,968 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:32:59,969 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:33:00,970 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:33:01,971 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:33:02,973 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:33:03,974 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:33:36,975 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-17 16:33:37,975 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:33:38,977 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:33:39,978 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:33:40,979 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:33:41,996 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:33:42,996 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:33:43,997 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:33:44,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:33:45,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:33:46,999 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:34:19,998 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-17 16:34:20,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:34:21,999 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:34:22,999 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:34:24,000 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:34:25,000 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:34:26,001 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:34:27,001 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:34:28,002 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:34:29,003 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:34:30,005 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:35:03,006 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-17 16:35:04,006 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:35:05,007 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:35:06,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:35:07,009 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:35:08,010 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:35:09,011 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:35:10,012 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:35:11,012 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:35:12,013 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:35:13,013 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:35:46,014 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-17 16:35:47,014 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:35:48,016 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:35:49,016 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:35:50,017 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:35:51,017 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:35:52,018 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:35:53,019 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:35:54,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:35:55,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:35:56,022 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:36:29,027 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-17 16:36:30,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:36:31,028 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:36:32,028 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:36:33,030 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:36:34,031 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:36:35,032 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:36:36,032 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:36:37,033 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:36:38,033 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:36:39,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:37:12,034 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-17 16:37:13,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:37:14,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:37:15,035 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:37:16,035 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:37:17,036 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:37:18,037 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:37:19,038 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:37:20,040 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:37:21,041 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:37:22,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:37:55,042 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-17 16:37:56,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:37:57,043 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:37:58,044 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:37:59,045 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:38:00,047 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:38:01,047 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:38:02,048 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:38:03,048 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:38:04,049 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:38:05,049 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:38:38,051 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-17 16:38:39,051 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:38:40,052 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:38:41,052 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:38:42,053 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:38:43,054 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:38:44,054 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:38:45,055 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:38:46,055 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:38:47,057 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:38:48,059 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:39:21,063 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-17 16:39:22,063 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:39:23,065 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:39:24,067 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:39:25,067 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:39:26,068 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:39:27,069 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:39:28,069 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:39:29,070 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:39:30,070 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:39:31,072 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:40:04,074 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-17 16:40:05,074 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:40:06,075 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:40:07,075 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:40:08,078 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:40:09,078 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:40:10,080 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:40:11,081 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:40:12,081 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:40:13,082 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:40:14,082 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:40:47,082 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-17 16:40:48,082 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:40:49,083 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:40:50,083 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:40:51,084 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:40:52,084 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:40:53,085 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:40:54,085 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:40:55,086 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:40:56,086 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:40:57,087 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:41:30,090 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-17 16:41:31,090 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:41:32,090 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:41:33,091 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:41:34,092 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:41:35,092 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:41:36,093 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:41:37,095 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:41:38,096 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:41:39,098 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:41:40,099 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:42:13,098 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-17 16:42:14,098 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:42:15,099 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:42:16,101 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:42:17,103 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:42:18,103 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:42:19,104 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:42:20,104 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:42:21,105 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:42:22,105 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:42:23,106 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:42:56,107 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-17 16:42:57,108 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:42:58,108 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:42:59,109 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:43:00,109 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:43:01,110 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:43:02,111 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:43:03,112 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:43:04,113 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:43:05,115 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:43:06,115 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:43:56,140 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-17 16:43:56,140 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); maxRetries=45
2017-03-17 16:43:57,140 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:43:58,142 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:43:59,142 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:44:00,143 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:44:01,144 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:44:02,144 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:44:03,145 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:44:04,146 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:44:05,147 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:44:06,148 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:44:56,162 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-17 16:44:56,162 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); maxRetries=45
2017-03-17 16:44:57,164 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:44:58,164 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:44:59,166 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:45:00,166 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:45:01,167 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:45:02,168 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:45:03,170 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:45:04,170 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:45:05,171 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:45:06,171 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:45:56,193 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-17 16:45:56,194 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); maxRetries=45
2017-03-17 16:45:57,194 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:45:58,195 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:45:59,197 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:46:00,197 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:46:01,199 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:46:02,201 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:46:03,203 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:46:04,203 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:46:05,204 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:46:06,204 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:46:56,222 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-17 16:46:56,222 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); maxRetries=45
2017-03-17 16:46:57,223 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:46:58,224 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:46:59,224 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:47:00,225 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:47:01,225 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:47:02,226 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:47:03,226 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:47:04,227 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:47:05,228 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:47:06,229 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:47:56,251 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-17 16:47:56,251 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); maxRetries=45
2017-03-17 16:47:57,251 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:47:58,252 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:47:59,252 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:48:00,254 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:48:01,256 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:48:02,256 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:48:03,257 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:48:04,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:48:05,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:48:06,259 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:48:56,283 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.107:8025 New: hadoop/192.168.43.6:8025
2017-03-17 16:48:56,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); maxRetries=45
2017-03-17 16:48:57,284 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:48:58,284 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:48:59,285 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:49:00,287 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:49:01,289 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:49:02,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:49:03,291 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:49:04,291 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:49:05,292 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:49:06,292 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-17 16:49:06,340 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-17 16:49:06,441 INFO org.apache.hadoop.ipc.Server: Stopping server on 53686
2017-03-17 16:49:06,441 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 53686
2017-03-17 16:49:06,441 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-17 16:49:06,443 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl is interrupted. Exiting.
2017-03-17 16:49:06,460 INFO org.apache.hadoop.ipc.Server: Stopping server on 8040
2017-03-17 16:49:06,461 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-17 16:49:06,461 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8040
2017-03-17 16:49:06,461 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Public cache exiting
2017-03-17 16:49:06,462 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NodeManager metrics system...
2017-03-17 16:49:06,462 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system stopped.
2017-03-17 16:49:06,462 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system shutdown complete.
2017-03-17 16:49:06,483 INFO org.apache.hadoop.util.ExitUtil: Exiting with status -1
2017-03-17 16:49:06,487 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NodeManager at gaurav-Inspiron-3542/127.0.1.1
************************************************************/
2017-03-18 10:09:05,247 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = gaurav-Inspiron-3542/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-digester-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsch-0.1.42.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-net-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.7.0_111
************************************************************/
2017-03-18 10:09:05,282 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2017-03-18 10:09:06,822 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2017-03-18 10:09:06,823 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2017-03-18 10:09:06,824 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2017-03-18 10:09:06,824 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2017-03-18 10:09:06,825 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2017-03-18 10:09:06,826 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2017-03-18 10:09:06,915 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2017-03-18 10:09:06,915 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2017-03-18 10:09:07,028 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-03-18 10:09:07,146 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-03-18 10:09:07,146 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2017-03-18 10:09:07,268 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2017-03-18 10:09:07,269 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2017-03-18 10:09:07,269 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2017-03-18 10:09:07,336 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/tmp/hadoop-hadoop/nm-local-dir/usercache_DEL_1489811947296
2017-03-18 10:09:07,442 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2017-03-18 10:09:07,495 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2017-03-18 10:09:07,495 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2017-03-18 10:09:07,595 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@23e033b0
2017-03-18 10:09:07,595 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2017-03-18 10:09:07,595 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2017-03-18 10:09:07,595 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2017-03-18 10:09:07,613 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (3.8 G). Thrashing might happen.
2017-03-18 10:09:07,644 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2017-03-18 10:09:07,846 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-18 10:09:07,882 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 55817
2017-03-18 10:09:08,134 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2017-03-18 10:09:08,134 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2017-03-18 10:09:08,135 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-18 10:09:08,135 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 55817: starting
2017-03-18 10:09:08,169 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : gaurav-Inspiron-3542:55817
2017-03-18 10:09:08,179 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-18 10:09:08,180 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2017-03-18 10:09:08,183 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2017-03-18 10:09:08,183 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-18 10:09:08,183 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2017-03-18 10:09:08,193 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2017-03-18 10:09:08,245 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2017-03-18 10:09:08,255 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2017-03-18 10:09:08,257 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at gaurav-Inspiron-3542/127.0.1.1:55817
2017-03-18 10:09:08,257 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2017-03-18 10:09:08,284 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2017-03-18 10:09:08,411 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-03-18 10:09:08,420 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-03-18 10:09:08,426 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2017-03-18 10:09:08,450 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-03-18 10:09:08,452 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2017-03-18 10:09:08,452 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-03-18 10:09:08,452 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-03-18 10:09:08,473 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /node/*
2017-03-18 10:09:08,473 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2017-03-18 10:09:08,889 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2017-03-18 10:09:08,928 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2017-03-18 10:09:08,928 INFO org.mortbay.log: jetty-6.1.26
2017-03-18 10:09:08,952 INFO org.mortbay.log: Extract jar:file:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2017-03-18 10:09:10,358 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-18 10:09:10,358 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2017-03-18 10:09:10,377 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /192.168.43.6:8025
2017-03-18 10:09:10,432 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out 0 NM container statuses: []
2017-03-18 10:09:10,443 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registering with RM using containers :[]
2017-03-18 10:09:10,561 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 985076593
2017-03-18 10:09:10,575 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id 2029260182
2017-03-18 10:09:10,576 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as gaurav-Inspiron-3542:55817 with total resource of <memory:8192, vCores:8>
2017-03-18 10:09:10,576 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2017-03-18 10:09:54,671 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-18 10:09:55,672 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-18 10:09:56,673 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-18 10:09:57,674 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-18 10:09:58,675 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-18 10:09:59,676 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-18 10:10:00,676 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-18 10:10:01,677 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-18 10:10:02,678 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-18 10:10:03,680 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-18 10:10:21,378 ERROR org.apache.hadoop.yarn.server.nodemanager.NodeManager: RECEIVED SIGNAL 15: SIGTERM
2017-03-18 10:10:21,408 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-18 10:10:21,508 INFO org.apache.hadoop.ipc.Server: Stopping server on 55817
2017-03-18 10:10:21,509 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 55817
2017-03-18 10:10:21,509 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-18 10:10:21,509 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl is interrupted. Exiting.
2017-03-18 10:10:21,516 INFO org.apache.hadoop.ipc.Server: Stopping server on 8040
2017-03-18 10:10:21,519 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8040
2017-03-18 10:10:21,519 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Public cache exiting
2017-03-18 10:10:21,519 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-18 10:10:21,520 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NodeManager metrics system...
2017-03-18 10:10:21,520 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system stopped.
2017-03-18 10:10:21,520 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system shutdown complete.
2017-03-18 10:10:21,520 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NodeManager at gaurav-Inspiron-3542/127.0.1.1
************************************************************/
2017-03-18 14:57:31,212 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = gaurav-Inspiron-3542/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-digester-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsch-0.1.42.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-net-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.7.0_111
************************************************************/
2017-03-18 14:57:31,261 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2017-03-18 14:57:32,340 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2017-03-18 14:57:32,341 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2017-03-18 14:57:32,350 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2017-03-18 14:57:32,351 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2017-03-18 14:57:32,351 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2017-03-18 14:57:32,352 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2017-03-18 14:57:32,375 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2017-03-18 14:57:32,375 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2017-03-18 14:57:32,415 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-03-18 14:57:32,487 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-03-18 14:57:32,487 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2017-03-18 14:57:32,564 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2017-03-18 14:57:32,566 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2017-03-18 14:57:32,566 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2017-03-18 14:57:32,597 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/tmp/hadoop-hadoop/nm-local-dir/usercache_DEL_1489829252569
2017-03-18 14:57:32,644 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2017-03-18 14:57:32,700 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2017-03-18 14:57:32,700 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2017-03-18 14:57:32,751 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@5986b474
2017-03-18 14:57:32,751 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2017-03-18 14:57:32,751 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2017-03-18 14:57:32,751 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2017-03-18 14:57:32,756 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (3.8 G). Thrashing might happen.
2017-03-18 14:57:32,760 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2017-03-18 14:57:33,019 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-18 14:57:33,049 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 56313
2017-03-18 14:57:33,096 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2017-03-18 14:57:33,097 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2017-03-18 14:57:33,097 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 56313: starting
2017-03-18 14:57:33,097 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-18 14:57:33,103 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : gaurav-Inspiron-3542:56313
2017-03-18 14:57:33,363 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-18 14:57:33,363 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2017-03-18 14:57:33,367 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2017-03-18 14:57:33,367 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-18 14:57:33,367 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2017-03-18 14:57:33,380 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2017-03-18 14:57:33,432 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2017-03-18 14:57:33,443 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2017-03-18 14:57:33,445 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at gaurav-Inspiron-3542/127.0.1.1:56313
2017-03-18 14:57:33,445 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2017-03-18 14:57:33,446 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2017-03-18 14:57:33,513 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-03-18 14:57:33,526 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-03-18 14:57:33,532 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2017-03-18 14:57:33,542 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-03-18 14:57:33,544 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2017-03-18 14:57:33,544 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-03-18 14:57:33,544 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-03-18 14:57:33,547 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /node/*
2017-03-18 14:57:33,547 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2017-03-18 14:57:33,881 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2017-03-18 14:57:33,883 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2017-03-18 14:57:33,883 INFO org.mortbay.log: jetty-6.1.26
2017-03-18 14:57:33,905 INFO org.mortbay.log: Extract jar:file:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2017-03-18 14:57:34,894 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-18 14:57:34,894 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2017-03-18 14:57:34,899 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /192.168.43.204:8025
2017-03-18 14:57:34,920 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out 0 NM container statuses: []
2017-03-18 14:57:34,924 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registering with RM using containers :[]
2017-03-18 14:57:36,394 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 49016510
2017-03-18 14:57:36,420 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id -148492259
2017-03-18 14:57:36,421 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as gaurav-Inspiron-3542:56313 with total resource of <memory:8192, vCores:8>
2017-03-18 14:57:36,422 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2017-03-18 21:08:29,650 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-18 21:08:29,690 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); maxRetries=45
2017-03-18 21:08:49,703 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); maxRetries=45
2017-03-18 21:09:09,724 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); maxRetries=45
2017-03-18 21:09:29,745 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); maxRetries=45
2017-03-18 21:09:49,766 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); maxRetries=45
2017-03-18 21:10:09,769 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); maxRetries=45
2017-03-18 21:10:29,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); maxRetries=45
2017-03-18 21:10:49,787 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); maxRetries=45
2017-03-18 21:11:09,808 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); maxRetries=45
2017-03-18 21:11:29,829 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); maxRetries=45
2017-03-18 21:11:49,850 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 10 time(s); maxRetries=45
2017-03-18 21:12:09,871 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 11 time(s); maxRetries=45
2017-03-18 21:12:29,892 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 12 time(s); maxRetries=45
2017-03-18 21:12:49,913 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 13 time(s); maxRetries=45
2017-03-18 21:13:09,934 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 14 time(s); maxRetries=45
2017-03-18 21:13:29,935 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 15 time(s); maxRetries=45
2017-03-18 21:13:49,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 16 time(s); maxRetries=45
2017-03-18 21:14:09,960 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 17 time(s); maxRetries=45
2017-03-18 21:14:29,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 18 time(s); maxRetries=45
2017-03-18 21:14:49,986 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 19 time(s); maxRetries=45
2017-03-18 21:15:10,007 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 20 time(s); maxRetries=45
2017-03-18 21:15:30,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 21 time(s); maxRetries=45
2017-03-18 21:15:50,048 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 22 time(s); maxRetries=45
2017-03-18 21:16:10,069 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 23 time(s); maxRetries=45
2017-03-18 21:16:30,091 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 24 time(s); maxRetries=45
2017-03-18 21:16:50,096 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 25 time(s); maxRetries=45
2017-03-18 21:17:10,117 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 26 time(s); maxRetries=45
2017-03-18 21:17:30,138 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 27 time(s); maxRetries=45
2017-03-18 21:17:50,159 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 28 time(s); maxRetries=45
2017-03-18 21:18:10,164 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 29 time(s); maxRetries=45
2017-03-18 21:18:30,178 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 30 time(s); maxRetries=45
2017-03-18 21:18:50,198 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 31 time(s); maxRetries=45
2017-03-18 21:19:10,218 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 32 time(s); maxRetries=45
2017-03-18 21:19:30,239 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 33 time(s); maxRetries=45
2017-03-18 21:19:50,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 34 time(s); maxRetries=45
2017-03-18 21:20:10,271 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 35 time(s); maxRetries=45
2017-03-18 21:20:30,272 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 36 time(s); maxRetries=45
2017-03-18 21:20:50,293 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 37 time(s); maxRetries=45
2017-03-18 21:21:10,314 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 38 time(s); maxRetries=45
2017-03-18 21:21:30,335 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 39 time(s); maxRetries=45
2017-03-18 21:21:50,356 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 40 time(s); maxRetries=45
2017-03-18 21:22:10,377 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 41 time(s); maxRetries=45
2017-03-18 21:22:30,391 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 42 time(s); maxRetries=45
2017-03-18 21:22:50,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 43 time(s); maxRetries=45
2017-03-18 21:23:10,418 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 44 time(s); maxRetries=45
2017-03-18 21:24:20,449 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-18 21:24:20,449 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); maxRetries=45
2017-03-18 21:24:40,464 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); maxRetries=45
2017-03-18 21:25:00,485 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); maxRetries=45
2017-03-18 21:25:20,502 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); maxRetries=45
2017-03-18 21:25:40,523 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); maxRetries=45
2017-03-18 21:26:00,535 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); maxRetries=45
2017-03-18 21:26:20,556 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); maxRetries=45
2017-03-18 21:26:40,568 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); maxRetries=45
2017-03-18 21:27:00,589 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); maxRetries=45
2017-03-18 21:27:20,595 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); maxRetries=45
2017-03-18 21:27:40,616 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 10 time(s); maxRetries=45
2017-03-18 21:28:00,634 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 11 time(s); maxRetries=45
2017-03-18 21:28:20,654 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 12 time(s); maxRetries=45
2017-03-18 21:28:40,670 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 13 time(s); maxRetries=45
2017-03-18 21:29:00,691 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 14 time(s); maxRetries=45
2017-03-18 21:29:20,695 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 15 time(s); maxRetries=45
2017-03-18 21:29:40,714 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 16 time(s); maxRetries=45
2017-03-18 21:30:00,734 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 17 time(s); maxRetries=45
2017-03-18 21:30:20,755 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 18 time(s); maxRetries=45
2017-03-18 21:30:40,756 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 19 time(s); maxRetries=45
2017-03-18 21:31:00,768 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 20 time(s); maxRetries=45
2017-03-18 21:31:20,789 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 21 time(s); maxRetries=45
2017-03-18 21:31:40,810 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 22 time(s); maxRetries=45
2017-03-18 21:32:00,827 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 23 time(s); maxRetries=45
2017-03-18 21:32:20,834 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 24 time(s); maxRetries=45
2017-03-18 21:32:40,855 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 25 time(s); maxRetries=45
2017-03-18 21:33:00,871 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 26 time(s); maxRetries=45
2017-03-18 21:33:20,884 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 27 time(s); maxRetries=45
2017-03-18 21:33:40,899 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 28 time(s); maxRetries=45
2017-03-18 21:34:00,917 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 29 time(s); maxRetries=45
2017-03-18 21:34:20,939 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 30 time(s); maxRetries=45
2017-03-18 21:34:40,960 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 31 time(s); maxRetries=45
2017-03-18 21:35:00,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 32 time(s); maxRetries=45
2017-03-18 21:35:21,002 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 33 time(s); maxRetries=45
2017-03-18 21:35:41,020 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 34 time(s); maxRetries=45
2017-03-18 21:36:01,041 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 35 time(s); maxRetries=45
2017-03-18 21:36:21,062 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 36 time(s); maxRetries=45
2017-03-18 21:36:41,078 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 37 time(s); maxRetries=45
2017-03-18 21:37:01,099 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 38 time(s); maxRetries=45
2017-03-18 21:37:21,119 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 39 time(s); maxRetries=45
2017-03-18 21:37:41,122 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 40 time(s); maxRetries=45
2017-03-18 21:38:01,143 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 41 time(s); maxRetries=45
2017-03-18 21:38:21,150 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 42 time(s); maxRetries=45
2017-03-18 21:38:41,156 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 43 time(s); maxRetries=45
2017-03-18 21:39:01,177 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 44 time(s); maxRetries=45
2017-03-18 21:40:11,206 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-18 21:40:11,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); maxRetries=45
2017-03-18 21:40:31,208 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); maxRetries=45
2017-03-18 21:40:51,219 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); maxRetries=45
2017-03-18 21:41:11,240 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); maxRetries=45
2017-03-18 21:41:31,261 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); maxRetries=45
2017-03-18 21:41:51,282 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); maxRetries=45
2017-03-18 21:42:11,303 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); maxRetries=45
2017-03-18 21:42:31,322 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); maxRetries=45
2017-03-18 21:42:51,332 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); maxRetries=45
2017-03-18 21:43:11,342 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); maxRetries=45
2017-03-18 21:43:31,346 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 10 time(s); maxRetries=45
2017-03-18 21:43:51,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 11 time(s); maxRetries=45
2017-03-18 21:44:11,373 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 12 time(s); maxRetries=45
2017-03-18 21:44:31,384 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 13 time(s); maxRetries=45
2017-03-18 21:44:51,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 14 time(s); maxRetries=45
2017-03-18 21:45:11,422 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 15 time(s); maxRetries=45
2017-03-18 21:45:31,443 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 16 time(s); maxRetries=45
2017-03-18 21:45:51,463 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 17 time(s); maxRetries=45
2017-03-18 21:46:11,484 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 18 time(s); maxRetries=45
2017-03-18 21:46:31,505 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 19 time(s); maxRetries=45
2017-03-18 21:46:51,526 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 20 time(s); maxRetries=45
2017-03-18 21:47:11,546 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 21 time(s); maxRetries=45
2017-03-18 21:47:31,562 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 22 time(s); maxRetries=45
2017-03-18 21:47:51,583 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 23 time(s); maxRetries=45
2017-03-18 21:48:11,604 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 24 time(s); maxRetries=45
2017-03-18 21:48:31,625 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 25 time(s); maxRetries=45
2017-03-18 21:48:51,646 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 26 time(s); maxRetries=45
2017-03-18 21:49:11,666 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 27 time(s); maxRetries=45
2017-03-18 21:49:31,674 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 28 time(s); maxRetries=45
2017-03-18 21:49:51,694 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 29 time(s); maxRetries=45
2017-03-18 21:50:11,702 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 30 time(s); maxRetries=45
2017-03-18 21:50:31,711 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 31 time(s); maxRetries=45
2017-03-18 21:50:51,727 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 32 time(s); maxRetries=45
2017-03-18 21:51:11,748 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 33 time(s); maxRetries=45
2017-03-18 21:51:31,766 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 34 time(s); maxRetries=45
2017-03-18 21:51:51,786 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 35 time(s); maxRetries=45
2017-03-18 21:52:11,798 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 36 time(s); maxRetries=45
2017-03-18 21:52:31,804 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 37 time(s); maxRetries=45
2017-03-18 21:52:51,810 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 38 time(s); maxRetries=45
2017-03-18 21:53:11,831 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 39 time(s); maxRetries=45
2017-03-18 21:53:31,839 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 40 time(s); maxRetries=45
2017-03-18 21:53:51,858 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 41 time(s); maxRetries=45
2017-03-18 21:54:11,878 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 42 time(s); maxRetries=45
2017-03-18 21:54:31,898 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 43 time(s); maxRetries=45
2017-03-18 21:54:51,909 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 44 time(s); maxRetries=45
2017-03-18 21:56:01,937 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-18 21:56:01,938 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); maxRetries=45
2017-03-18 21:56:21,941 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); maxRetries=45
2017-03-18 21:56:41,961 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); maxRetries=45
2017-03-18 21:57:01,977 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); maxRetries=45
2017-03-18 21:57:21,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); maxRetries=45
2017-03-18 21:57:42,000 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); maxRetries=45
2017-03-18 21:58:02,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); maxRetries=45
2017-03-18 21:58:22,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); maxRetries=45
2017-03-18 21:58:42,050 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); maxRetries=45
2017-03-18 21:59:02,066 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); maxRetries=45
2017-03-18 21:59:22,087 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 10 time(s); maxRetries=45
2017-03-18 21:59:42,095 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 11 time(s); maxRetries=45
2017-03-18 22:00:02,116 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 12 time(s); maxRetries=45
2017-03-18 22:00:22,137 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 13 time(s); maxRetries=45
2017-03-18 22:00:42,158 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 14 time(s); maxRetries=45
2017-03-18 22:01:02,179 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 15 time(s); maxRetries=45
2017-03-18 22:01:22,198 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 16 time(s); maxRetries=45
2017-03-18 22:01:42,210 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 17 time(s); maxRetries=45
2017-03-18 22:02:02,215 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 18 time(s); maxRetries=45
2017-03-18 22:02:22,236 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 19 time(s); maxRetries=45
2017-03-18 22:02:42,257 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 20 time(s); maxRetries=45
2017-03-18 22:03:02,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 21 time(s); maxRetries=45
2017-03-18 22:03:22,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 22 time(s); maxRetries=45
2017-03-18 22:03:42,298 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 23 time(s); maxRetries=45
2017-03-18 22:04:02,314 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 24 time(s); maxRetries=45
2017-03-18 22:04:22,329 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 25 time(s); maxRetries=45
2017-03-18 22:04:42,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 26 time(s); maxRetries=45
2017-03-18 22:05:02,335 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 27 time(s); maxRetries=45
2017-03-18 22:05:22,354 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 28 time(s); maxRetries=45
2017-03-18 22:05:42,356 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 29 time(s); maxRetries=45
2017-03-18 22:06:02,377 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 30 time(s); maxRetries=45
2017-03-18 22:06:22,398 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 31 time(s); maxRetries=45
2017-03-18 22:06:42,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 32 time(s); maxRetries=45
2017-03-18 22:07:02,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 33 time(s); maxRetries=45
2017-03-18 22:07:22,424 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 34 time(s); maxRetries=45
2017-03-18 22:07:42,445 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 35 time(s); maxRetries=45
2017-03-18 22:08:02,461 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 36 time(s); maxRetries=45
2017-03-18 22:08:22,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 37 time(s); maxRetries=45
2017-03-18 22:08:42,490 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 38 time(s); maxRetries=45
2017-03-18 22:09:02,511 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 39 time(s); maxRetries=45
2017-03-18 22:09:22,515 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 40 time(s); maxRetries=45
2017-03-18 22:09:42,536 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 41 time(s); maxRetries=45
2017-03-18 22:10:02,556 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 42 time(s); maxRetries=45
2017-03-18 22:10:22,576 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 43 time(s); maxRetries=45
2017-03-18 22:10:42,597 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 44 time(s); maxRetries=45
2017-03-18 22:11:52,639 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-18 22:11:52,639 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); maxRetries=45
2017-03-18 22:12:12,659 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); maxRetries=45
2017-03-18 22:12:32,681 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); maxRetries=45
2017-03-18 22:12:52,702 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); maxRetries=45
2017-03-18 22:13:12,723 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); maxRetries=45
2017-03-18 22:13:32,733 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); maxRetries=45
2017-03-18 22:13:52,755 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); maxRetries=45
2017-03-18 22:14:12,775 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); maxRetries=45
2017-03-18 22:14:32,783 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); maxRetries=45
2017-03-18 22:14:52,798 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); maxRetries=45
2017-03-18 22:15:12,801 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 10 time(s); maxRetries=45
2017-03-18 22:15:32,804 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 11 time(s); maxRetries=45
2017-03-18 22:15:52,815 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 12 time(s); maxRetries=45
2017-03-18 22:16:12,836 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 13 time(s); maxRetries=45
2017-03-18 22:16:32,857 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 14 time(s); maxRetries=45
2017-03-18 22:16:52,870 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 15 time(s); maxRetries=45
2017-03-18 22:17:12,883 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 16 time(s); maxRetries=45
2017-03-18 22:17:32,890 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 17 time(s); maxRetries=45
2017-03-18 22:17:52,898 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 18 time(s); maxRetries=45
2017-03-18 22:18:12,919 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 19 time(s); maxRetries=45
2017-03-18 22:18:32,940 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 20 time(s); maxRetries=45
2017-03-18 22:18:52,943 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 21 time(s); maxRetries=45
2017-03-18 22:19:12,965 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 22 time(s); maxRetries=45
2017-03-18 22:19:32,971 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 23 time(s); maxRetries=45
2017-03-18 22:19:52,992 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 24 time(s); maxRetries=45
2017-03-18 22:20:13,013 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 25 time(s); maxRetries=45
2017-03-18 22:20:33,020 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 26 time(s); maxRetries=45
2017-03-18 22:20:53,032 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 27 time(s); maxRetries=45
2017-03-18 22:21:13,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 28 time(s); maxRetries=45
2017-03-18 22:21:33,055 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 29 time(s); maxRetries=45
2017-03-18 22:21:53,076 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 30 time(s); maxRetries=45
2017-03-18 22:22:13,078 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 31 time(s); maxRetries=45
2017-03-18 22:22:33,091 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 32 time(s); maxRetries=45
2017-03-18 22:22:53,112 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 33 time(s); maxRetries=45
2017-03-18 22:23:13,117 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 34 time(s); maxRetries=45
2017-03-18 22:23:33,138 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 35 time(s); maxRetries=45
2017-03-18 22:23:53,155 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 36 time(s); maxRetries=45
2017-03-18 22:24:13,176 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 37 time(s); maxRetries=45
2017-03-18 22:24:33,197 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 38 time(s); maxRetries=45
2017-03-18 22:24:53,218 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 39 time(s); maxRetries=45
2017-03-18 22:25:13,238 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 40 time(s); maxRetries=45
2017-03-18 22:25:33,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 41 time(s); maxRetries=45
2017-03-18 22:25:53,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 42 time(s); maxRetries=45
2017-03-18 22:26:13,270 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 43 time(s); maxRetries=45
2017-03-18 22:26:33,273 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 44 time(s); maxRetries=45
2017-03-18 22:27:43,293 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-18 22:27:43,293 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); maxRetries=45
2017-03-18 22:28:03,314 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); maxRetries=45
2017-03-18 22:28:23,331 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); maxRetries=45
2017-03-18 22:28:43,351 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); maxRetries=45
2017-03-18 22:29:03,359 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); maxRetries=45
2017-03-18 22:29:23,379 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); maxRetries=45
2017-03-18 22:29:43,400 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); maxRetries=45
2017-03-18 22:30:03,418 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); maxRetries=45
2017-03-18 22:30:23,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); maxRetries=45
2017-03-18 22:30:43,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); maxRetries=45
2017-03-18 22:31:03,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 10 time(s); maxRetries=45
2017-03-18 22:31:23,497 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 11 time(s); maxRetries=45
2017-03-18 22:31:43,513 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 12 time(s); maxRetries=45
2017-03-18 22:32:03,521 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 13 time(s); maxRetries=45
2017-03-18 22:32:23,527 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 14 time(s); maxRetries=45
2017-03-18 22:32:43,547 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 15 time(s); maxRetries=45
2017-03-18 22:33:03,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 16 time(s); maxRetries=45
2017-03-18 22:33:23,570 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 17 time(s); maxRetries=45
2017-03-18 22:33:43,589 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 18 time(s); maxRetries=45
2017-03-18 22:34:03,601 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 19 time(s); maxRetries=45
2017-03-18 22:34:23,606 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 20 time(s); maxRetries=45
2017-03-18 22:34:43,626 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 21 time(s); maxRetries=45
2017-03-18 22:35:03,629 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 22 time(s); maxRetries=45
2017-03-18 22:35:23,648 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 23 time(s); maxRetries=45
2017-03-18 22:35:43,669 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 24 time(s); maxRetries=45
2017-03-18 22:36:03,671 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 25 time(s); maxRetries=45
2017-03-18 22:36:23,689 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 26 time(s); maxRetries=45
2017-03-18 22:36:43,703 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 27 time(s); maxRetries=45
2017-03-18 22:37:03,722 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 28 time(s); maxRetries=45
2017-03-18 22:37:23,743 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 29 time(s); maxRetries=45
2017-03-18 22:37:43,744 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 30 time(s); maxRetries=45
2017-03-18 22:38:03,763 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 31 time(s); maxRetries=45
2017-03-18 22:38:23,765 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 32 time(s); maxRetries=45
2017-03-18 22:38:43,766 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 33 time(s); maxRetries=45
2017-03-18 22:39:03,786 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 34 time(s); maxRetries=45
2017-03-18 22:39:23,792 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 35 time(s); maxRetries=45
2017-03-18 22:39:43,802 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 36 time(s); maxRetries=45
2017-03-18 22:40:03,823 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 37 time(s); maxRetries=45
2017-03-18 22:40:23,844 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 38 time(s); maxRetries=45
2017-03-18 22:40:43,865 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 39 time(s); maxRetries=45
2017-03-18 22:41:03,886 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 40 time(s); maxRetries=45
2017-03-18 22:41:23,906 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 41 time(s); maxRetries=45
2017-03-18 22:41:43,927 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 42 time(s); maxRetries=45
2017-03-18 22:42:03,945 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 43 time(s); maxRetries=45
2017-03-18 22:42:23,966 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 44 time(s); maxRetries=45
2017-03-18 22:43:33,997 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-18 22:43:33,997 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); maxRetries=45
2017-03-18 22:43:54,018 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); maxRetries=45
2017-03-18 22:44:14,039 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); maxRetries=45
2017-03-18 22:44:34,059 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); maxRetries=45
2017-03-18 22:44:54,078 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); maxRetries=45
2017-03-18 22:45:14,099 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); maxRetries=45
2017-03-18 22:45:34,120 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); maxRetries=45
2017-03-18 22:45:54,141 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); maxRetries=45
2017-03-18 22:46:14,162 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); maxRetries=45
2017-03-18 22:46:34,182 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); maxRetries=45
2017-03-18 22:46:54,188 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 10 time(s); maxRetries=45
2017-03-18 22:47:14,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 11 time(s); maxRetries=45
2017-03-18 22:47:34,227 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 12 time(s); maxRetries=45
2017-03-18 22:47:54,248 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 13 time(s); maxRetries=45
2017-03-18 22:48:14,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 14 time(s); maxRetries=45
2017-03-18 22:48:34,271 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 15 time(s); maxRetries=45
2017-03-18 22:48:54,280 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 16 time(s); maxRetries=45
2017-03-18 22:49:14,282 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 17 time(s); maxRetries=45
2017-03-18 22:49:34,293 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 18 time(s); maxRetries=45
2017-03-18 22:49:54,301 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 19 time(s); maxRetries=45
2017-03-18 22:50:14,322 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 20 time(s); maxRetries=45
2017-03-18 22:50:34,342 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 21 time(s); maxRetries=45
2017-03-18 22:50:54,364 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 22 time(s); maxRetries=45
2017-03-18 22:51:14,385 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 23 time(s); maxRetries=45
2017-03-18 22:51:34,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 24 time(s); maxRetries=45
2017-03-18 22:51:54,422 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 25 time(s); maxRetries=45
2017-03-18 22:52:14,443 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 26 time(s); maxRetries=45
2017-03-18 22:52:34,463 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 27 time(s); maxRetries=45
2017-03-18 22:52:54,485 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 28 time(s); maxRetries=45
2017-03-18 22:53:14,494 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 29 time(s); maxRetries=45
2017-03-18 22:53:34,510 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 30 time(s); maxRetries=45
2017-03-18 22:53:54,521 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 31 time(s); maxRetries=45
2017-03-18 22:54:14,529 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 32 time(s); maxRetries=45
2017-03-18 22:54:34,550 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 33 time(s); maxRetries=45
2017-03-18 22:54:54,571 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 34 time(s); maxRetries=45
2017-03-18 22:55:14,592 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 35 time(s); maxRetries=45
2017-03-18 22:55:34,613 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 36 time(s); maxRetries=45
2017-03-18 22:55:54,633 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 37 time(s); maxRetries=45
2017-03-18 22:56:14,638 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 38 time(s); maxRetries=45
2017-03-18 22:56:34,640 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 39 time(s); maxRetries=45
2017-03-18 22:56:54,660 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 40 time(s); maxRetries=45
2017-03-18 22:57:14,662 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 41 time(s); maxRetries=45
2017-03-18 22:57:34,676 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 42 time(s); maxRetries=45
2017-03-18 22:57:54,694 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 43 time(s); maxRetries=45
2017-03-18 22:58:14,707 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 44 time(s); maxRetries=45
2017-03-18 22:59:24,727 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-18 22:59:24,727 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); maxRetries=45
2017-03-18 22:59:44,728 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); maxRetries=45
2017-03-18 23:00:04,746 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); maxRetries=45
2017-03-18 23:00:24,766 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); maxRetries=45
2017-03-18 23:00:44,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); maxRetries=45
2017-03-18 23:01:04,794 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); maxRetries=45
2017-03-18 23:01:24,810 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); maxRetries=45
2017-03-18 23:01:44,831 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); maxRetries=45
2017-03-18 23:02:04,851 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); maxRetries=45
2017-03-18 23:02:24,855 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); maxRetries=45
2017-03-18 23:02:44,876 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 10 time(s); maxRetries=45
2017-03-18 23:03:04,897 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 11 time(s); maxRetries=45
2017-03-18 23:03:24,905 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 12 time(s); maxRetries=45
2017-03-18 23:03:44,910 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 13 time(s); maxRetries=45
2017-03-18 23:04:04,920 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 14 time(s); maxRetries=45
2017-03-18 23:04:24,941 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 15 time(s); maxRetries=45
2017-03-18 23:04:44,955 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 16 time(s); maxRetries=45
2017-03-18 23:05:04,976 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 17 time(s); maxRetries=45
2017-03-18 23:05:24,990 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 18 time(s); maxRetries=45
2017-03-18 23:05:45,011 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 19 time(s); maxRetries=45
2017-03-18 23:06:05,014 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 20 time(s); maxRetries=45
2017-03-18 23:06:25,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 21 time(s); maxRetries=45
2017-03-18 23:06:45,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 22 time(s); maxRetries=45
2017-03-18 23:07:05,061 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 23 time(s); maxRetries=45
2017-03-18 23:07:25,078 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 24 time(s); maxRetries=45
2017-03-18 23:07:45,099 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 25 time(s); maxRetries=45
2017-03-18 23:08:05,120 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 26 time(s); maxRetries=45
2017-03-18 23:08:25,127 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 27 time(s); maxRetries=45
2017-03-18 23:08:45,141 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 28 time(s); maxRetries=45
2017-03-18 23:09:05,162 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 29 time(s); maxRetries=45
2017-03-18 23:09:25,183 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 30 time(s); maxRetries=45
2017-03-18 23:09:45,204 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 31 time(s); maxRetries=45
2017-03-18 23:10:05,218 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 32 time(s); maxRetries=45
2017-03-18 23:10:25,239 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 33 time(s); maxRetries=45
2017-03-18 23:10:45,259 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 34 time(s); maxRetries=45
2017-03-18 23:11:05,280 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 35 time(s); maxRetries=45
2017-03-18 23:11:25,302 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 36 time(s); maxRetries=45
2017-03-18 23:11:45,323 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 37 time(s); maxRetries=45
2017-03-18 23:12:05,344 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 38 time(s); maxRetries=45
2017-03-18 23:12:25,365 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 39 time(s); maxRetries=45
2017-03-18 23:12:45,379 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 40 time(s); maxRetries=45
2017-03-18 23:13:05,389 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 41 time(s); maxRetries=45
2017-03-18 23:13:25,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 42 time(s); maxRetries=45
2017-03-18 23:13:45,410 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 43 time(s); maxRetries=45
2017-03-18 23:14:05,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 44 time(s); maxRetries=45
2017-03-18 23:15:15,466 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-18 23:15:15,467 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); maxRetries=45
2017-03-18 23:15:35,487 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); maxRetries=45
2017-03-18 23:15:55,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); maxRetries=45
2017-03-18 23:16:15,529 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); maxRetries=45
2017-03-18 23:16:35,546 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); maxRetries=45
2017-03-18 23:16:55,558 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); maxRetries=45
2017-03-18 23:17:15,578 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); maxRetries=45
2017-03-18 23:17:35,599 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); maxRetries=45
2017-03-18 23:17:55,620 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); maxRetries=45
2017-03-18 23:18:15,640 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); maxRetries=45
2017-03-18 23:18:26,337 ERROR org.apache.hadoop.yarn.server.nodemanager.NodeManager: RECEIVED SIGNAL 15: SIGTERM
2017-03-22 13:14:29,241 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = gaurav-Inspiron-3542/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-digester-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsch-0.1.42.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-net-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.7.0_111
************************************************************/
2017-03-22 13:14:29,276 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2017-03-22 13:14:30,368 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2017-03-22 13:14:30,370 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2017-03-22 13:14:30,370 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2017-03-22 13:14:30,371 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2017-03-22 13:14:30,372 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2017-03-22 13:14:30,373 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2017-03-22 13:14:30,401 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2017-03-22 13:14:30,402 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2017-03-22 13:14:30,451 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-03-22 13:14:30,538 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-03-22 13:14:30,538 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2017-03-22 13:14:30,645 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2017-03-22 13:14:30,647 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2017-03-22 13:14:30,647 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2017-03-22 13:14:30,670 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2017-03-22 13:14:30,713 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2017-03-22 13:14:30,713 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2017-03-22 13:14:30,766 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@31789ec6
2017-03-22 13:14:30,766 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2017-03-22 13:14:30,766 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2017-03-22 13:14:30,766 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2017-03-22 13:14:30,771 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (3.8 G). Thrashing might happen.
2017-03-22 13:14:30,777 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2017-03-22 13:14:30,833 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-22 13:14:30,852 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 38657
2017-03-22 13:14:30,896 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2017-03-22 13:14:30,896 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2017-03-22 13:14:30,896 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-22 13:14:30,896 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 38657: starting
2017-03-22 13:14:30,907 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : gaurav-Inspiron-3542:38657
2017-03-22 13:14:30,916 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-22 13:14:30,916 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2017-03-22 13:14:30,920 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2017-03-22 13:14:30,921 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2017-03-22 13:14:30,921 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-22 13:14:30,922 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2017-03-22 13:14:30,960 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2017-03-22 13:14:30,970 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2017-03-22 13:14:30,971 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at gaurav-Inspiron-3542/127.0.1.1:38657
2017-03-22 13:14:30,972 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2017-03-22 13:14:30,973 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2017-03-22 13:14:31,039 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-03-22 13:14:31,050 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-03-22 13:14:31,056 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2017-03-22 13:14:31,065 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-03-22 13:14:31,067 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2017-03-22 13:14:31,067 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-03-22 13:14:31,067 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-03-22 13:14:31,071 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /node/*
2017-03-22 13:14:31,071 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2017-03-22 13:14:31,396 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2017-03-22 13:14:31,397 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2017-03-22 13:14:31,398 INFO org.mortbay.log: jetty-6.1.26
2017-03-22 13:14:31,418 INFO org.mortbay.log: Extract jar:file:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2017-03-22 13:14:32,440 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-22 13:14:32,440 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2017-03-22 13:14:32,493 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /192.168.43.204:8025
2017-03-22 13:14:32,515 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out 0 NM container statuses: []
2017-03-22 13:14:32,519 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registering with RM using containers :[]
2017-03-22 13:14:35,567 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 13:14:36,570 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:14:36,769 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id -1527856682
2017-03-22 13:14:36,772 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id -147133666
2017-03-22 13:14:36,773 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as gaurav-Inspiron-3542:38657 with total resource of <memory:8192, vCores:8>
2017-03-22 13:14:36,773 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2017-03-22 13:15:52,500 ERROR org.apache.hadoop.yarn.server.nodemanager.NodeManager: RECEIVED SIGNAL 15: SIGTERM
2017-03-22 13:15:52,504 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-22 13:15:52,605 INFO org.apache.hadoop.ipc.Server: Stopping server on 38657
2017-03-22 13:15:52,606 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 38657
2017-03-22 13:15:52,606 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-22 13:15:52,607 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl is interrupted. Exiting.
2017-03-22 13:15:52,621 INFO org.apache.hadoop.ipc.Server: Stopping server on 8040
2017-03-22 13:15:52,622 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8040
2017-03-22 13:15:52,622 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NodeManager metrics system...
2017-03-22 13:15:52,622 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Public cache exiting
2017-03-22 13:15:52,623 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-22 13:15:52,623 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system stopped.
2017-03-22 13:15:52,624 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system shutdown complete.
2017-03-22 13:15:52,624 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NodeManager at gaurav-Inspiron-3542/127.0.1.1
************************************************************/
2017-03-22 13:19:48,435 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = gaurav-Inspiron-3542/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-digester-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsch-0.1.42.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-net-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.7.0_111
************************************************************/
2017-03-22 13:19:48,443 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2017-03-22 13:19:49,472 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2017-03-22 13:19:49,473 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2017-03-22 13:19:49,474 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2017-03-22 13:19:49,474 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2017-03-22 13:19:49,475 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2017-03-22 13:19:49,475 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2017-03-22 13:19:49,495 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2017-03-22 13:19:49,495 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2017-03-22 13:19:49,527 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-03-22 13:19:49,584 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-03-22 13:19:49,584 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2017-03-22 13:19:49,604 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2017-03-22 13:19:49,605 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2017-03-22 13:19:49,606 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2017-03-22 13:19:49,632 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/tmp/hadoop-hadoop/nm-local-dir/usercache_DEL_1490168989608
2017-03-22 13:19:49,675 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2017-03-22 13:19:49,695 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2017-03-22 13:19:49,695 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2017-03-22 13:19:49,726 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@23e033b0
2017-03-22 13:19:49,726 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2017-03-22 13:19:49,726 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2017-03-22 13:19:49,726 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2017-03-22 13:19:49,730 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (3.8 G). Thrashing might happen.
2017-03-22 13:19:49,734 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2017-03-22 13:19:50,021 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-22 13:19:50,036 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 57086
2017-03-22 13:19:50,078 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2017-03-22 13:19:50,078 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2017-03-22 13:19:50,079 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-22 13:19:50,079 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 57086: starting
2017-03-22 13:19:50,085 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : gaurav-Inspiron-3542:57086
2017-03-22 13:19:50,093 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-22 13:19:50,093 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2017-03-22 13:19:50,096 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2017-03-22 13:19:50,097 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-22 13:19:50,097 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2017-03-22 13:19:50,097 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2017-03-22 13:19:50,108 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2017-03-22 13:19:50,118 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2017-03-22 13:19:50,120 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at gaurav-Inspiron-3542/127.0.1.1:57086
2017-03-22 13:19:50,120 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2017-03-22 13:19:50,121 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2017-03-22 13:19:50,185 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-03-22 13:19:50,197 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-03-22 13:19:50,203 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2017-03-22 13:19:50,212 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-03-22 13:19:50,216 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2017-03-22 13:19:50,216 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-03-22 13:19:50,216 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-03-22 13:19:50,220 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /node/*
2017-03-22 13:19:50,220 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2017-03-22 13:19:50,535 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2017-03-22 13:19:50,537 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2017-03-22 13:19:50,537 INFO org.mortbay.log: jetty-6.1.26
2017-03-22 13:19:50,558 INFO org.mortbay.log: Extract jar:file:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2017-03-22 13:19:51,651 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-22 13:19:51,651 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2017-03-22 13:19:51,656 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /192.168.43.204:8025
2017-03-22 13:19:51,678 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out 0 NM container statuses: []
2017-03-22 13:19:51,683 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registering with RM using containers :[]
2017-03-22 13:19:55,052 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 13:19:56,054 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:19:56,198 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 576741756
2017-03-22 13:19:56,200 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id -1784042617
2017-03-22 13:19:56,201 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as gaurav-Inspiron-3542:57086 with total resource of <memory:8192, vCores:8>
2017-03-22 13:19:56,201 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2017-03-22 13:24:05,937 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 13:24:06,937 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:24:07,938 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:24:08,939 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:24:09,940 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:24:10,942 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:24:11,942 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:24:12,944 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:24:13,945 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:24:14,946 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:24:15,947 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:24:45,953 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 13:24:46,954 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:24:47,955 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:24:48,956 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:24:49,957 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:24:50,958 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:24:51,959 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:24:52,960 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:24:53,961 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:24:54,962 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:24:55,963 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:25:25,989 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 13:25:26,989 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:25:27,990 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:25:28,991 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:25:29,992 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:25:30,992 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:25:31,993 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:25:32,993 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:25:33,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:25:34,995 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:25:35,995 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:26:06,000 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 13:26:07,000 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:26:08,001 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:26:09,002 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:26:10,002 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:26:11,003 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:26:11,236 WARN org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Node is out of sync with ResourceManager, hence resyncing.
2017-03-22 13:26:11,236 WARN org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Message from ResourceManager: Node not found resyncing gaurav-Inspiron-3542:57086
2017-03-22 13:26:11,238 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: Notifying ContainerManager to block new container-requests
2017-03-22 13:26:11,238 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: Preserving containers on resync
2017-03-22 13:26:12,237 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out 0 NM container statuses: []
2017-03-22 13:26:12,237 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registering with RM using containers :[]
2017-03-22 13:26:12,271 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id -1474879068
2017-03-22 13:26:12,271 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id 1259178293
2017-03-22 13:26:12,271 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as gaurav-Inspiron-3542:57086 with total resource of <memory:8192, vCores:8>
2017-03-22 13:26:12,271 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2017-03-22 13:26:12,272 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: NodeStatusUpdater thread is reRegistered and restarted
2017-03-22 13:41:16,037 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 13:41:17,037 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:41:18,038 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:41:19,039 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:41:20,040 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:41:21,041 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:41:22,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:41:23,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:41:24,043 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:41:25,044 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:41:26,045 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:41:56,497 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 13:41:57,498 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:41:58,499 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:41:59,500 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:42:00,501 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:42:01,502 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:42:02,503 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:42:03,504 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:42:04,504 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:42:05,505 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:42:06,505 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:42:36,510 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 13:42:37,511 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:42:38,511 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:42:39,512 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:42:40,513 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:42:41,514 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:42:42,515 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:42:43,516 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:42:44,517 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:42:45,518 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:42:46,519 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:43:17,272 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 13:43:18,272 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:43:18,279 WARN org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Node is out of sync with ResourceManager, hence resyncing.
2017-03-22 13:43:18,279 WARN org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Message from ResourceManager: Node not found resyncing gaurav-Inspiron-3542:57086
2017-03-22 13:43:18,279 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: Notifying ContainerManager to block new container-requests
2017-03-22 13:43:18,279 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: Preserving containers on resync
2017-03-22 13:43:19,279 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out 0 NM container statuses: []
2017-03-22 13:43:19,279 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registering with RM using containers :[]
2017-03-22 13:43:19,283 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 1825944838
2017-03-22 13:43:19,283 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id -1669734814
2017-03-22 13:43:19,283 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as gaurav-Inspiron-3542:57086 with total resource of <memory:8192, vCores:8>
2017-03-22 13:43:19,283 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2017-03-22 13:43:19,283 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: NodeStatusUpdater thread is reRegistered and restarted
2017-03-22 13:47:56,528 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 13:47:57,529 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:47:58,530 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:47:59,531 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:48:00,532 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:48:01,533 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:48:02,533 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:48:03,534 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:48:04,535 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:48:05,535 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:48:06,536 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:48:36,958 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 13:48:37,958 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:48:38,959 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:48:39,960 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:48:40,961 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:48:41,961 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:48:42,962 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:48:43,963 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:48:44,964 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:48:45,965 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:48:46,966 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:49:18,075 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 13:49:19,076 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:49:20,076 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:49:21,077 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:49:22,079 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:49:23,080 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:49:24,081 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:49:25,081 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:49:26,082 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:49:27,083 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:49:28,083 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:50:05,432 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 13:50:06,433 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:50:07,434 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:50:08,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:50:09,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:50:10,437 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:50:11,438 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:50:12,439 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:50:13,440 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:50:14,441 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:50:15,442 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:50:45,774 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 13:50:46,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:50:47,775 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:50:48,776 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:50:49,777 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:50:50,778 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:50:51,778 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:50:52,779 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:50:53,780 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:50:54,781 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:50:55,782 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:51:25,937 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 13:51:26,937 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:51:27,938 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:51:28,939 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:51:29,939 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:51:30,940 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:51:31,941 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:51:32,942 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:51:33,943 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:51:34,944 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:51:35,944 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:52:06,368 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 13:52:07,369 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:52:08,370 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:52:09,371 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:52:10,372 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:52:11,373 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:52:12,374 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:52:13,374 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:52:14,375 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:52:15,376 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:52:16,377 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:52:47,221 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 13:52:48,221 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:52:49,222 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:52:50,223 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:52:51,224 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:52:52,225 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:52:53,226 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:52:54,227 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:52:55,228 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:52:56,229 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:52:57,229 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:53:27,585 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 13:53:28,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:53:29,586 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:53:30,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:53:31,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:53:32,588 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:53:33,589 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:53:34,590 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:53:35,591 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:53:36,592 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:53:37,593 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:54:07,908 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 13:54:08,908 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:54:09,909 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:54:10,910 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:54:11,911 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:54:12,912 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:54:13,913 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:54:14,914 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:54:15,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:54:16,916 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:54:17,916 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:54:48,255 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 13:54:49,255 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:54:50,256 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:54:51,256 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:54:52,257 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:54:53,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:54:54,259 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:54:55,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:54:56,261 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:54:57,262 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:54:58,262 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:55:28,600 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 13:55:29,600 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:55:30,601 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:55:31,602 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:55:32,602 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:55:33,603 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:55:34,603 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:55:35,604 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:55:36,604 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:55:37,605 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:55:38,606 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:56:08,610 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 13:56:09,611 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:56:10,612 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:56:11,613 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:56:12,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:56:13,615 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:56:14,616 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:56:15,616 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:56:16,617 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:56:17,619 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:56:18,620 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:56:48,877 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 13:56:49,877 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:56:50,878 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:56:51,879 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:56:52,880 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:56:53,881 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:56:54,882 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:56:55,882 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:56:56,883 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:56:57,884 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:56:58,884 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:57:29,221 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 13:57:30,222 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:57:31,223 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:57:32,224 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:57:33,224 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:57:34,225 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:57:35,226 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:57:36,226 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:57:37,227 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:57:38,228 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:57:39,228 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:58:13,361 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 13:58:14,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:58:15,363 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:58:16,364 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:58:17,365 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:58:18,365 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:58:19,366 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:58:20,367 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:58:21,367 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:58:22,368 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:58:23,369 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:58:53,805 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 13:58:54,805 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:58:55,806 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:58:56,807 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:58:57,808 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:58:58,808 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:58:59,809 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:59:00,809 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:59:01,810 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:59:02,811 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:59:03,812 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:59:34,973 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 13:59:35,974 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:59:36,974 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:59:37,975 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:59:38,976 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:59:39,977 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:59:40,978 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:59:41,979 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:59:42,980 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:59:43,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 13:59:44,982 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:00:15,314 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 14:00:16,314 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:00:17,314 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:00:18,315 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:00:19,316 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:00:20,317 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:00:21,318 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:00:22,318 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:00:23,319 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:00:24,320 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:00:25,321 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:00:55,329 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 14:00:56,329 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:00:57,330 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:00:58,330 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:00:59,331 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:01:00,332 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:01:01,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:01:02,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:01:03,334 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:01:04,335 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:01:05,336 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:01:35,340 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 14:01:36,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:01:37,341 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:01:38,342 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:01:39,343 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:01:40,344 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:01:41,345 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:01:42,346 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:01:43,347 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:01:44,348 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:01:45,349 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:02:16,453 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 14:02:17,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:02:18,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:02:19,455 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:02:20,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:02:21,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:02:22,457 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:02:23,458 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:02:24,458 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:02:25,459 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:02:26,460 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:02:56,491 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 14:02:57,491 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:02:58,492 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:02:59,493 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:03:00,494 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:03:01,495 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:03:02,496 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:03:03,497 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:03:04,497 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:03:05,498 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:03:06,499 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:03:36,504 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 14:03:37,504 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:03:38,505 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:03:39,506 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:03:40,507 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:03:41,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:03:42,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:03:43,509 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:03:44,510 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:03:45,511 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:03:46,512 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:04:16,592 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 14:04:17,592 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:04:18,592 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:04:19,593 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:04:20,594 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:04:21,595 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:04:22,596 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:04:23,597 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:04:24,598 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:04:25,599 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:04:26,600 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:05:00,614 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 14:05:01,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:05:02,615 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:05:03,616 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:05:04,617 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:05:05,618 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:05:06,619 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:05:07,620 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:05:08,621 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:05:09,621 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:05:10,622 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:05:40,731 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 14:05:41,731 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:05:42,732 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:05:43,732 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:05:44,733 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:05:45,734 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:05:46,734 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:05:47,735 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:05:48,736 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:05:49,737 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:05:50,738 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:06:21,517 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 14:06:22,518 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:06:23,518 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:06:24,519 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:06:25,519 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:06:26,520 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:06:27,521 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:06:28,522 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:06:29,522 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:06:30,523 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:06:31,524 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:07:02,034 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 14:07:03,035 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:07:04,036 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:07:05,037 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:07:06,038 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:07:07,039 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:07:08,040 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:07:09,041 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:07:10,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:07:11,043 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:07:12,044 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:07:42,897 WARN org.apache.hadoop.ipc.Client: Address change detected. Old: hadoop/192.168.43.204:8025 New: hadoop/192.168.43.6:8025
2017-03-22 14:07:43,898 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:07:44,899 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:07:45,900 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:07:46,901 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:07:47,902 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:07:48,902 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:07:49,903 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:07:50,904 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:07:51,905 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:07:52,906 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: hadoop/192.168.43.6:8025. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 14:07:52,916 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-22 14:07:53,017 INFO org.apache.hadoop.ipc.Server: Stopping server on 57086
2017-03-22 14:07:53,018 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 57086
2017-03-22 14:07:53,018 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl is interrupted. Exiting.
2017-03-22 14:07:53,020 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-22 14:07:53,041 INFO org.apache.hadoop.ipc.Server: Stopping server on 8040
2017-03-22 14:07:53,041 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-22 14:07:53,041 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8040
2017-03-22 14:07:53,042 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Public cache exiting
2017-03-22 14:07:53,042 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NodeManager metrics system...
2017-03-22 14:07:53,042 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system stopped.
2017-03-22 14:07:53,043 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system shutdown complete.
2017-03-22 14:07:53,058 INFO org.apache.hadoop.util.ExitUtil: Exiting with status -1
2017-03-22 14:07:53,059 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NodeManager at gaurav-Inspiron-3542/127.0.1.1
************************************************************/
2017-03-22 18:52:26,472 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = gaurav-Inspiron-3542/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-digester-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsch-0.1.42.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-net-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.7.0_111
************************************************************/
2017-03-22 18:52:26,481 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2017-03-22 18:52:27,558 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2017-03-22 18:52:27,559 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2017-03-22 18:52:27,559 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2017-03-22 18:52:27,559 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2017-03-22 18:52:27,560 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2017-03-22 18:52:27,560 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2017-03-22 18:52:27,582 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2017-03-22 18:52:27,582 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2017-03-22 18:52:27,614 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-03-22 18:52:27,672 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-03-22 18:52:27,672 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2017-03-22 18:52:27,712 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2017-03-22 18:52:27,713 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2017-03-22 18:52:27,713 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2017-03-22 18:52:27,754 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/tmp/hadoop-hadoop/nm-local-dir/usercache_DEL_1490188947716
2017-03-22 18:52:27,832 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2017-03-22 18:52:27,853 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2017-03-22 18:52:27,853 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2017-03-22 18:52:27,898 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@396729a9
2017-03-22 18:52:27,898 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2017-03-22 18:52:27,898 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2017-03-22 18:52:27,898 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2017-03-22 18:52:27,902 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (3.8 G). Thrashing might happen.
2017-03-22 18:52:27,906 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2017-03-22 18:52:27,941 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-22 18:52:27,957 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 45699
2017-03-22 18:52:28,012 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2017-03-22 18:52:28,012 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2017-03-22 18:52:28,013 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-22 18:52:28,013 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 45699: starting
2017-03-22 18:52:28,019 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : gaurav-Inspiron-3542:45699
2017-03-22 18:52:28,029 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-22 18:52:28,030 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2017-03-22 18:52:28,033 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2017-03-22 18:52:28,033 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2017-03-22 18:52:28,033 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-22 18:52:28,034 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2017-03-22 18:52:28,046 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2017-03-22 18:52:28,057 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2017-03-22 18:52:28,058 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at gaurav-Inspiron-3542/127.0.1.1:45699
2017-03-22 18:52:28,058 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2017-03-22 18:52:28,060 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2017-03-22 18:52:28,130 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-03-22 18:52:28,140 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-03-22 18:52:28,145 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2017-03-22 18:52:28,152 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-03-22 18:52:28,155 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2017-03-22 18:52:28,155 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-03-22 18:52:28,156 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-03-22 18:52:28,159 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /node/*
2017-03-22 18:52:28,159 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2017-03-22 18:52:28,508 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2017-03-22 18:52:28,511 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2017-03-22 18:52:28,511 INFO org.mortbay.log: jetty-6.1.26
2017-03-22 18:52:28,532 INFO org.mortbay.log: Extract jar:file:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2017-03-22 18:52:29,489 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-22 18:52:29,489 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2017-03-22 18:52:29,495 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8031
2017-03-22 18:52:29,517 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out 0 NM container statuses: []
2017-03-22 18:52:29,522 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registering with RM using containers :[]
2017-03-22 18:52:29,696 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id -429152335
2017-03-22 18:52:29,712 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id -1042302582
2017-03-22 18:52:29,712 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as gaurav-Inspiron-3542:45699 with total resource of <memory:8192, vCores:8>
2017-03-22 18:52:29,712 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2017-03-22 19:13:07,092 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 19:13:08,093 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 19:13:09,095 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 19:13:10,096 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 19:13:11,097 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 19:13:12,098 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 19:13:13,099 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 19:13:13,310 ERROR org.apache.hadoop.yarn.server.nodemanager.NodeManager: RECEIVED SIGNAL 15: SIGTERM
2017-03-22 19:13:14,101 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 19:13:15,101 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 19:13:16,102 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-03-22 19:13:16,130 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-22 19:13:16,231 INFO org.apache.hadoop.ipc.Server: Stopping server on 45699
2017-03-22 19:13:16,232 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-22 19:13:16,232 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 45699
2017-03-22 19:13:16,233 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl is interrupted. Exiting.
2017-03-22 19:13:16,248 INFO org.apache.hadoop.ipc.Server: Stopping server on 8040
2017-03-22 19:13:16,249 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8040
2017-03-22 19:13:16,249 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-22 19:13:16,251 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Public cache exiting
2017-03-22 19:13:16,252 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NodeManager metrics system...
2017-03-22 19:13:16,253 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system stopped.
2017-03-22 19:13:16,254 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system shutdown complete.
2017-03-22 19:13:16,254 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NodeManager at gaurav-Inspiron-3542/127.0.1.1
************************************************************/
2017-03-22 19:16:51,793 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = gaurav-Inspiron-3542/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-digester-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsch-0.1.42.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-net-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.7.0_111
************************************************************/
2017-03-22 19:16:51,802 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2017-03-22 19:16:52,951 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2017-03-22 19:16:52,952 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2017-03-22 19:16:52,953 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2017-03-22 19:16:52,954 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2017-03-22 19:16:52,954 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2017-03-22 19:16:52,955 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2017-03-22 19:16:52,986 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2017-03-22 19:16:52,986 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2017-03-22 19:16:53,036 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-03-22 19:16:53,120 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-03-22 19:16:53,120 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2017-03-22 19:16:53,151 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2017-03-22 19:16:53,153 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2017-03-22 19:16:53,153 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2017-03-22 19:16:53,183 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/tmp/hadoop-hadoop/nm-local-dir/usercache_DEL_1490190413156
2017-03-22 19:16:53,257 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2017-03-22 19:16:53,285 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2017-03-22 19:16:53,286 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2017-03-22 19:16:53,322 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@23e033b0
2017-03-22 19:16:53,322 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2017-03-22 19:16:53,322 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2017-03-22 19:16:53,322 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2017-03-22 19:16:53,326 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (3.8 G). Thrashing might happen.
2017-03-22 19:16:53,330 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2017-03-22 19:16:53,363 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-22 19:16:53,378 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 46458
2017-03-22 19:16:53,423 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2017-03-22 19:16:53,423 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2017-03-22 19:16:53,424 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-22 19:16:53,424 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 46458: starting
2017-03-22 19:16:53,431 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : gaurav-Inspiron-3542:46458
2017-03-22 19:16:53,440 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-22 19:16:53,441 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2017-03-22 19:16:53,444 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2017-03-22 19:16:53,444 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2017-03-22 19:16:53,444 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-22 19:16:53,446 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2017-03-22 19:16:53,458 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2017-03-22 19:16:53,469 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2017-03-22 19:16:53,471 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at gaurav-Inspiron-3542/127.0.1.1:46458
2017-03-22 19:16:53,472 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2017-03-22 19:16:53,473 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2017-03-22 19:16:53,542 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-03-22 19:16:53,556 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-03-22 19:16:53,562 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2017-03-22 19:16:53,572 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-03-22 19:16:53,575 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2017-03-22 19:16:53,575 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-03-22 19:16:53,575 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-03-22 19:16:53,578 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /node/*
2017-03-22 19:16:53,578 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2017-03-22 19:16:53,912 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2017-03-22 19:16:53,914 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2017-03-22 19:16:53,914 INFO org.mortbay.log: jetty-6.1.26
2017-03-22 19:16:53,935 INFO org.mortbay.log: Extract jar:file:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2017-03-22 19:16:54,882 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-22 19:16:54,882 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2017-03-22 19:16:54,888 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8031
2017-03-22 19:16:54,909 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out 0 NM container statuses: []
2017-03-22 19:16:54,914 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registering with RM using containers :[]
2017-03-22 19:16:55,086 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id -1117099562
2017-03-22 19:16:55,088 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id 345187177
2017-03-22 19:16:55,088 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as gaurav-Inspiron-3542:46458 with total resource of <memory:8192, vCores:8>
2017-03-22 19:16:55,088 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2017-03-23 01:30:05,346 ERROR org.apache.hadoop.yarn.server.nodemanager.NodeManager: RECEIVED SIGNAL 15: SIGTERM
2017-03-23 01:30:07,319 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-23 01:30:07,420 INFO org.apache.hadoop.ipc.Server: Stopping server on 46458
2017-03-23 01:30:07,612 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 46458
2017-03-23 01:30:07,613 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-23 01:30:07,613 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl is interrupted. Exiting.
2017-03-23 01:30:08,385 INFO org.apache.hadoop.ipc.Server: Stopping server on 8040
2017-03-23 01:30:08,449 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-23 01:30:08,883 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Public cache exiting
2017-03-23 01:30:08,883 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8040
2017-03-23 01:30:08,883 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NodeManager metrics system...
2017-03-23 01:30:09,108 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system stopped.
2017-03-23 01:30:09,108 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system shutdown complete.
2017-03-23 01:30:09,109 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NodeManager at gaurav-Inspiron-3542/127.0.1.1
************************************************************/
2017-03-23 14:23:08,279 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = gaurav-Inspiron-3542/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-digester-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsch-0.1.42.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-net-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.7.0_111
************************************************************/
2017-03-23 14:23:08,324 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2017-03-23 14:23:10,124 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2017-03-23 14:23:10,126 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2017-03-23 14:23:10,135 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2017-03-23 14:23:10,136 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2017-03-23 14:23:10,137 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2017-03-23 14:23:10,138 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2017-03-23 14:23:10,192 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2017-03-23 14:23:10,193 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2017-03-23 14:23:10,269 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-03-23 14:23:10,411 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-03-23 14:23:10,411 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2017-03-23 14:23:10,611 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2017-03-23 14:23:10,612 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2017-03-23 14:23:10,613 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2017-03-23 14:23:10,653 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2017-03-23 14:23:10,720 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2017-03-23 14:23:10,720 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2017-03-23 14:23:10,828 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@37b87e7e
2017-03-23 14:23:10,828 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2017-03-23 14:23:10,828 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2017-03-23 14:23:10,829 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2017-03-23 14:23:10,833 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (3.8 G). Thrashing might happen.
2017-03-23 14:23:10,838 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2017-03-23 14:23:10,908 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-23 14:23:10,950 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 51863
2017-03-23 14:23:11,009 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2017-03-23 14:23:11,009 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2017-03-23 14:23:11,015 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-23 14:23:11,015 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 51863: starting
2017-03-23 14:23:11,114 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : gaurav-Inspiron-3542:51863
2017-03-23 14:23:11,126 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-23 14:23:11,131 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2017-03-23 14:23:11,140 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2017-03-23 14:23:11,150 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-23 14:23:11,159 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2017-03-23 14:23:11,175 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2017-03-23 14:23:11,244 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2017-03-23 14:23:11,273 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2017-03-23 14:23:11,280 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at gaurav-Inspiron-3542/127.0.1.1:51863
2017-03-23 14:23:11,280 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2017-03-23 14:23:11,281 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2017-03-23 14:23:11,376 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-03-23 14:23:11,387 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-03-23 14:23:11,404 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2017-03-23 14:23:11,418 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-03-23 14:23:11,421 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2017-03-23 14:23:11,421 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-03-23 14:23:11,421 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-03-23 14:23:11,426 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /node/*
2017-03-23 14:23:11,426 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2017-03-23 14:23:11,904 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2017-03-23 14:23:11,907 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2017-03-23 14:23:11,907 INFO org.mortbay.log: jetty-6.1.26
2017-03-23 14:23:11,941 INFO org.mortbay.log: Extract jar:file:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2017-03-23 14:23:13,574 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-23 14:23:13,574 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2017-03-23 14:23:13,601 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8031
2017-03-23 14:23:13,649 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out 0 NM container statuses: []
2017-03-23 14:23:13,663 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registering with RM using containers :[]
2017-03-23 14:23:13,984 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id -1723039543
2017-03-23 14:23:13,987 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id 157135493
2017-03-23 14:23:13,988 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as gaurav-Inspiron-3542:51863 with total resource of <memory:8192, vCores:8>
2017-03-23 14:23:13,988 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2017-03-23 14:52:41,973 ERROR org.apache.hadoop.yarn.server.nodemanager.NodeManager: RECEIVED SIGNAL 15: SIGTERM
2017-03-23 14:52:51,254 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-23 14:52:51,384 INFO org.apache.hadoop.ipc.Server: Stopping server on 51863
2017-03-24 18:51:49,583 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = gaurav-Inspiron-3542/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-digester-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsch-0.1.42.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-net-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.7.0_111
************************************************************/
2017-03-24 18:51:49,611 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2017-03-24 18:51:50,718 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2017-03-24 18:51:50,720 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2017-03-24 18:51:50,720 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2017-03-24 18:51:50,721 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2017-03-24 18:51:50,722 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2017-03-24 18:51:50,722 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2017-03-24 18:51:50,750 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2017-03-24 18:51:50,750 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2017-03-24 18:51:50,788 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-03-24 18:51:50,849 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-03-24 18:51:50,849 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2017-03-24 18:51:50,935 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2017-03-24 18:51:50,937 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2017-03-24 18:51:50,937 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2017-03-24 18:51:50,965 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2017-03-24 18:51:51,017 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2017-03-24 18:51:51,017 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2017-03-24 18:51:51,077 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@68c34b0
2017-03-24 18:51:51,077 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2017-03-24 18:51:51,077 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2017-03-24 18:51:51,077 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2017-03-24 18:51:51,083 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (3.8 G). Thrashing might happen.
2017-03-24 18:51:51,089 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2017-03-24 18:51:51,163 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-24 18:51:51,181 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 33250
2017-03-24 18:51:51,225 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2017-03-24 18:51:51,225 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2017-03-24 18:51:51,226 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-24 18:51:51,226 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 33250: starting
2017-03-24 18:51:51,249 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : gaurav-Inspiron-3542:33250
2017-03-24 18:51:51,285 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-24 18:51:51,285 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2017-03-24 18:51:51,291 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2017-03-24 18:51:51,291 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-24 18:51:51,291 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2017-03-24 18:51:51,292 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2017-03-24 18:51:51,339 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2017-03-24 18:51:51,349 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2017-03-24 18:51:51,350 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at gaurav-Inspiron-3542/127.0.1.1:33250
2017-03-24 18:51:51,350 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2017-03-24 18:51:51,352 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2017-03-24 18:51:51,415 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-03-24 18:51:51,424 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-03-24 18:51:51,429 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2017-03-24 18:51:51,436 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-03-24 18:51:51,438 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2017-03-24 18:51:51,438 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-03-24 18:51:51,439 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-03-24 18:51:51,443 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /node/*
2017-03-24 18:51:51,443 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2017-03-24 18:51:51,758 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2017-03-24 18:51:51,761 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2017-03-24 18:51:51,761 INFO org.mortbay.log: jetty-6.1.26
2017-03-24 18:51:51,783 INFO org.mortbay.log: Extract jar:file:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2017-03-24 18:51:52,937 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-24 18:51:52,937 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2017-03-24 18:51:52,958 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8031
2017-03-24 18:51:52,980 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out 0 NM container statuses: []
2017-03-24 18:51:52,984 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registering with RM using containers :[]
2017-03-24 18:51:53,186 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 1948181034
2017-03-24 18:51:53,189 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id -267465448
2017-03-24 18:51:53,189 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as gaurav-Inspiron-3542:33250 with total resource of <memory:8192, vCores:8>
2017-03-24 18:51:53,189 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2017-03-24 22:01:43,801 ERROR org.apache.hadoop.yarn.server.nodemanager.NodeManager: RECEIVED SIGNAL 15: SIGTERM
2017-03-24 22:01:44,180 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-24 22:01:44,281 INFO org.apache.hadoop.ipc.Server: Stopping server on 33250
2017-03-24 22:01:44,281 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 33250
2017-03-24 22:01:44,281 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-24 22:01:44,282 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl is interrupted. Exiting.
2017-03-24 22:01:44,565 INFO org.apache.hadoop.ipc.Server: Stopping server on 8040
2017-03-24 22:01:44,565 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8040
2017-03-24 22:01:44,566 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-24 22:01:44,566 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Public cache exiting
2017-03-24 22:01:44,566 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NodeManager metrics system...
2017-03-24 22:01:44,566 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system stopped.
2017-03-24 22:01:44,566 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system shutdown complete.
2017-03-24 22:01:44,567 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NodeManager at gaurav-Inspiron-3542/127.0.1.1
************************************************************/
2017-03-24 22:04:03,298 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = gaurav-Inspiron-3542/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-digester-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsch-0.1.42.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-net-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.7.0_111
************************************************************/
2017-03-24 22:04:03,313 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2017-03-24 22:04:04,337 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2017-03-24 22:04:04,339 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2017-03-24 22:04:04,340 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2017-03-24 22:04:04,340 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2017-03-24 22:04:04,340 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2017-03-24 22:04:04,341 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2017-03-24 22:04:04,362 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2017-03-24 22:04:04,363 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2017-03-24 22:04:04,396 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-03-24 22:04:04,457 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-03-24 22:04:04,457 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2017-03-24 22:04:04,529 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2017-03-24 22:04:04,530 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2017-03-24 22:04:04,530 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2017-03-24 22:04:04,550 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2017-03-24 22:04:04,594 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2017-03-24 22:04:04,594 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2017-03-24 22:04:04,671 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@5ed7122b
2017-03-24 22:04:04,671 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2017-03-24 22:04:04,671 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2017-03-24 22:04:04,671 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2017-03-24 22:04:04,675 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (3.8 G). Thrashing might happen.
2017-03-24 22:04:04,681 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2017-03-24 22:04:04,779 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-24 22:04:04,795 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 47517
2017-03-24 22:04:04,837 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2017-03-24 22:04:04,837 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2017-03-24 22:04:04,838 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-24 22:04:04,838 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 47517: starting
2017-03-24 22:04:04,854 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : gaurav-Inspiron-3542:47517
2017-03-24 22:04:04,888 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-24 22:04:04,888 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2017-03-24 22:04:04,892 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2017-03-24 22:04:04,892 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-24 22:04:04,892 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2017-03-24 22:04:04,893 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2017-03-24 22:04:04,940 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2017-03-24 22:04:04,950 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2017-03-24 22:04:04,952 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at gaurav-Inspiron-3542/127.0.1.1:47517
2017-03-24 22:04:04,952 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2017-03-24 22:04:04,953 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2017-03-24 22:04:05,015 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-03-24 22:04:05,024 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-03-24 22:04:05,029 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2017-03-24 22:04:05,036 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-03-24 22:04:05,038 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2017-03-24 22:04:05,038 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-03-24 22:04:05,038 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-03-24 22:04:05,041 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /node/*
2017-03-24 22:04:05,041 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2017-03-24 22:04:05,345 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2017-03-24 22:04:05,347 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2017-03-24 22:04:05,347 INFO org.mortbay.log: jetty-6.1.26
2017-03-24 22:04:05,370 INFO org.mortbay.log: Extract jar:file:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2017-03-24 22:04:06,300 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-24 22:04:06,301 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2017-03-24 22:04:06,318 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8031
2017-03-24 22:04:06,338 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out 0 NM container statuses: []
2017-03-24 22:04:06,342 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registering with RM using containers :[]
2017-03-24 22:04:06,525 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 1288586336
2017-03-24 22:04:06,540 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id -350866003
2017-03-24 22:04:06,540 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as gaurav-Inspiron-3542:47517 with total resource of <memory:8192, vCores:8>
2017-03-24 22:04:06,540 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2017-03-24 22:07:46,374 ERROR org.apache.hadoop.yarn.server.nodemanager.NodeManager: RECEIVED SIGNAL 15: SIGTERM
2017-03-24 22:07:46,386 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-24 22:07:46,489 INFO org.apache.hadoop.ipc.Server: Stopping server on 47517
2017-03-24 22:07:46,490 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 47517
2017-03-24 22:07:46,490 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-24 22:07:46,491 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl is interrupted. Exiting.
2017-03-24 22:07:46,497 INFO org.apache.hadoop.ipc.Server: Stopping server on 8040
2017-03-24 22:07:46,498 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8040
2017-03-24 22:07:46,499 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-24 22:07:46,499 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Public cache exiting
2017-03-24 22:07:46,499 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NodeManager metrics system...
2017-03-24 22:07:46,500 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system stopped.
2017-03-24 22:07:46,500 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system shutdown complete.
2017-03-24 22:07:46,500 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NodeManager at gaurav-Inspiron-3542/127.0.1.1
************************************************************/
2017-03-24 23:52:56,981 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = gaurav-Inspiron-3542/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-digester-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsch-0.1.42.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-net-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.7.0_111
************************************************************/
2017-03-24 23:52:57,002 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2017-03-24 23:52:58,085 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2017-03-24 23:52:58,086 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2017-03-24 23:52:58,087 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2017-03-24 23:52:58,087 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2017-03-24 23:52:58,088 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2017-03-24 23:52:58,088 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2017-03-24 23:52:58,110 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2017-03-24 23:52:58,111 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2017-03-24 23:52:58,151 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-03-24 23:52:58,217 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-03-24 23:52:58,217 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2017-03-24 23:52:58,327 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2017-03-24 23:52:58,329 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2017-03-24 23:52:58,329 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2017-03-24 23:52:58,352 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2017-03-24 23:52:58,405 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2017-03-24 23:52:58,405 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2017-03-24 23:52:58,454 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@65fff289
2017-03-24 23:52:58,454 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2017-03-24 23:52:58,454 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2017-03-24 23:52:58,454 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2017-03-24 23:52:58,458 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (3.8 G). Thrashing might happen.
2017-03-24 23:52:58,462 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2017-03-24 23:52:58,510 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-24 23:52:58,526 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 49419
2017-03-24 23:52:58,570 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2017-03-24 23:52:58,570 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2017-03-24 23:52:58,570 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-24 23:52:58,570 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 49419: starting
2017-03-24 23:52:58,582 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : gaurav-Inspiron-3542:49419
2017-03-24 23:52:58,590 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-24 23:52:58,591 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2017-03-24 23:52:58,595 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2017-03-24 23:52:58,595 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-24 23:52:58,595 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2017-03-24 23:52:58,596 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2017-03-24 23:52:58,647 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2017-03-24 23:52:58,657 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2017-03-24 23:52:58,659 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at gaurav-Inspiron-3542/127.0.1.1:49419
2017-03-24 23:52:58,659 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2017-03-24 23:52:58,660 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2017-03-24 23:52:58,725 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-03-24 23:52:58,737 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-03-24 23:52:58,743 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2017-03-24 23:52:58,752 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-03-24 23:52:58,755 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2017-03-24 23:52:58,755 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-03-24 23:52:58,755 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-03-24 23:52:58,759 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /node/*
2017-03-24 23:52:58,759 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2017-03-24 23:52:59,104 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2017-03-24 23:52:59,106 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2017-03-24 23:52:59,106 INFO org.mortbay.log: jetty-6.1.26
2017-03-24 23:52:59,127 INFO org.mortbay.log: Extract jar:file:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2017-03-24 23:53:00,257 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-24 23:53:00,257 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2017-03-24 23:53:00,279 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8031
2017-03-24 23:53:00,300 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out 0 NM container statuses: []
2017-03-24 23:53:00,305 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registering with RM using containers :[]
2017-03-24 23:53:00,507 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id -510184319
2017-03-24 23:53:00,509 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id -1601068283
2017-03-24 23:53:00,510 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as gaurav-Inspiron-3542:49419 with total resource of <memory:8192, vCores:8>
2017-03-24 23:53:00,510 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2017-03-25 00:52:00,347 ERROR org.apache.hadoop.yarn.server.nodemanager.NodeManager: RECEIVED SIGNAL 15: SIGTERM
2017-03-25 00:52:00,787 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-25 00:52:00,888 INFO org.apache.hadoop.ipc.Server: Stopping server on 49419
2017-03-25 00:52:00,890 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 49419
2017-03-25 00:52:00,890 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-25 00:52:00,890 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl is interrupted. Exiting.
2017-03-25 00:52:00,977 INFO org.apache.hadoop.ipc.Server: Stopping server on 8040
2017-03-25 00:52:00,978 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8040
2017-03-25 00:52:00,978 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-25 00:52:00,978 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Public cache exiting
2017-03-25 00:52:00,978 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NodeManager metrics system...
2017-03-25 00:52:00,979 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system stopped.
2017-03-25 00:52:00,979 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system shutdown complete.
2017-03-25 00:52:00,979 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NodeManager at gaurav-Inspiron-3542/127.0.1.1
************************************************************/
2017-03-25 11:05:18,616 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = gaurav-Inspiron-3542/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.3
STARTUP_MSG:   classpath = /home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-digester-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/gson-2.2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsch-0.1.42.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jsp-api-2.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-net-3.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/lib/hadoop-auth-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/common/hadoop-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.3-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/contrib/capacity-scheduler/*.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-common-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-api-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-registry-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-client-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/javax.inject-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/asm-3.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jettison-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/activation-1.1.jar:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/lib/xz-1.0.jar:/home/hadoop/Desktop/hadoop-2.7.3/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r baa91f7c6bc9cb92be5982de4719c1c8af91ccff; compiled by 'root' on 2016-08-18T01:41Z
STARTUP_MSG:   java = 1.7.0_111
************************************************************/
2017-03-25 11:05:18,638 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2017-03-25 11:05:19,719 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2017-03-25 11:05:19,720 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2017-03-25 11:05:19,721 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2017-03-25 11:05:19,721 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2017-03-25 11:05:19,722 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2017-03-25 11:05:19,722 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2017-03-25 11:05:19,742 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2017-03-25 11:05:19,743 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2017-03-25 11:05:19,774 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-03-25 11:05:19,830 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-03-25 11:05:19,830 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2017-03-25 11:05:19,906 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2017-03-25 11:05:19,907 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2017-03-25 11:05:19,907 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2017-03-25 11:05:19,928 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2017-03-25 11:05:19,973 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2017-03-25 11:05:19,973 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2017-03-25 11:05:20,014 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@1be0be0d
2017-03-25 11:05:20,015 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2017-03-25 11:05:20,015 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2017-03-25 11:05:20,015 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2017-03-25 11:05:20,018 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (3.8 G). Thrashing might happen.
2017-03-25 11:05:20,024 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2017-03-25 11:05:20,303 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-25 11:05:20,318 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 47357
2017-03-25 11:05:20,361 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2017-03-25 11:05:20,361 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2017-03-25 11:05:20,362 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-25 11:05:20,362 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 47357: starting
2017-03-25 11:05:20,408 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : gaurav-Inspiron-3542:47357
2017-03-25 11:05:20,604 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-03-25 11:05:20,605 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2017-03-25 11:05:20,614 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2017-03-25 11:05:20,614 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-25 11:05:20,615 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2017-03-25 11:05:20,616 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2017-03-25 11:05:20,724 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2017-03-25 11:05:20,735 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2017-03-25 11:05:20,736 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at gaurav-Inspiron-3542/127.0.1.1:47357
2017-03-25 11:05:20,736 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2017-03-25 11:05:20,738 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2017-03-25 11:05:20,797 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-03-25 11:05:20,806 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-03-25 11:05:20,810 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2017-03-25 11:05:20,818 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-03-25 11:05:20,820 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2017-03-25 11:05:20,820 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-03-25 11:05:20,820 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-03-25 11:05:20,823 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /node/*
2017-03-25 11:05:20,824 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2017-03-25 11:05:21,114 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2017-03-25 11:05:21,116 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2017-03-25 11:05:21,116 INFO org.mortbay.log: jetty-6.1.26
2017-03-25 11:05:21,137 INFO org.mortbay.log: Extract jar:file:/home/hadoop/Desktop/hadoop-2.7.3/share/hadoop/yarn/hadoop-yarn-common-2.7.3.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2017-03-25 11:05:22,168 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-25 11:05:22,168 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app node started at 8042
2017-03-25 11:05:22,195 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8031
2017-03-25 11:05:22,215 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out 0 NM container statuses: []
2017-03-25 11:05:22,219 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registering with RM using containers :[]
2017-03-25 11:05:22,414 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 1129221667
2017-03-25 11:05:22,428 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id -1412206096
2017-03-25 11:05:22,429 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as gaurav-Inspiron-3542:47357 with total resource of <memory:8192, vCores:8>
2017-03-25 11:05:22,429 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2017-03-25 11:51:36,163 ERROR org.apache.hadoop.yarn.server.nodemanager.NodeManager: RECEIVED SIGNAL 15: SIGTERM
2017-03-25 11:51:36,269 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2017-03-25 11:51:36,370 INFO org.apache.hadoop.ipc.Server: Stopping server on 47357
2017-03-25 11:51:36,371 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 47357
2017-03-25 11:51:36,371 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-25 11:51:36,371 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl is interrupted. Exiting.
2017-03-25 11:51:36,379 INFO org.apache.hadoop.ipc.Server: Stopping server on 8040
2017-03-25 11:51:36,379 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8040
2017-03-25 11:51:36,379 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2017-03-25 11:51:36,379 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Public cache exiting
2017-03-25 11:51:36,380 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NodeManager metrics system...
2017-03-25 11:51:36,380 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system stopped.
2017-03-25 11:51:36,380 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system shutdown complete.
2017-03-25 11:51:36,380 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NodeManager at gaurav-Inspiron-3542/127.0.1.1
************************************************************/
